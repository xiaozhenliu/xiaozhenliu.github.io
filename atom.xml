<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[刘虓震的技术笔记]]></title>
  <subtitle><![CDATA[Live in the Future, then Build What's Missing]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://tech.liuxiaozhen.com/"/>
  <updated>2016-08-21T10:39:23.000Z</updated>
  <id>http://tech.liuxiaozhen.com/</id>
  
  <author>
    <name><![CDATA[Liu Xiaozhen]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Machine Learning By Stanford University Week 6]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/06/25/Machine-Learning-W6/"/>
    <id>http://tech.liuxiaozhen.com/2016/06/25/Machine-Learning-W6/</id>
    <published>2016-06-25T14:24:12.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<h1 id="6-_Machine_Learning_Application_Advice_and_System_Design">6. Machine Learning Application Advice and System Design</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5E94;&#x7528;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x4E8B;&#x9879;&#x4EE5;&#x53CA;&#x7CFB;&#x7EDF;&#x8BBE;&#x8BA1;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 May session.</strong></p>
<h2 id="6-1_Evaluating_a_Learning_Algorithm">6.1 Evaluating a Learning Algorithm</h2><p>Goal: Learn How to choose one of the most promising avenues to spend your time pursuing. </p>
<h3 id="6-1-1_Deciding_what_to_try_next">6.1.1 Deciding what to try next</h3><p><strong>Debugging a learning algorithm</strong></p>
<p>Suppose you have implemented regularized linear regression to predict housing prices. </p>
<p>However, when you test your hypothesis on a new set of hourses, you find that it makes unacceptably large errors in its predictions. What should you try next?</p>
<ul>
<li>Get more training examples</li>
<li>Try smaller sets of features </li>
<li>Try getting additional features</li>
<li>Try adding polynomial features $(x_1^2, x_2^2, x_1x_2, \text{etc})$</li>
<li>Try decreasing $\lambda$</li>
<li>Try increasing $\lambda$  </li>
</ul>
<p>WRONG: Randomly pick one of these options</p>
<p>CORRECT: Machine Learning Diagnostic</p>
<p>A test that you can run to gain insight what is/isn&#x2019;t working with a learning algorithm, and gain guidance as to how best to improve its performance. </p>
<h3 id="6-1-2_Evaluating_a_Hypothesis">6.1.2 Evaluating a Hypothesis</h3><p>Example: Using housing sizes to predict prices.</p>
<p>Method: (randomly) choose 70% of the dataset (samples) as the training set, the other 30% as the test set. </p>
<p>Training set: $m$ number of samples; $x^{(1)},y^{(1)}&#x2026;x^{(m)},y^{(m)}$</p>
<p>Test set: $m_test$ number of samples<br>$x_{test}^{(1)},y_{test}^{(1)}&#x2026;x_{test}^{(m)},y_{text}^{(m)}$</p>
<p><strong>Training/testing procedure for linear regression</strong></p>
<ul>
<li>Learn parameter $\theta$ from training data (minimizing training error $J(\theta)$)</li>
<li>Compute test set error: </li>
</ul>
<p>$$J_{test}(\theta)=\frac1{2m_{test}}\sum_{i=1}^{m_{test}}\left(h_\theta(x_{test}^{(i)})-y_{test}^{(i)}\right)^2$$</p>
<p>$$J_{test}(\theta)=\frac1{2m_{test}}\sum_{i=1}^{m_{test}}y_{test}^{(i)}\log h_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})\log h_\theta(x_{test}^{(i)})$$</p>
<ul>
<li>Misclassification error (0/1 misclassification error);</li>
</ul>
<p>$$err(h_\theta(x),y)=\begin{cases}1\quad\text{if }h_\theta(x)\geq0.5, y=0\text{ or if } h_\theta(x)\leq0.5, y=1\0\quad\text{otherwise}\end{cases}$$</p>
<p>$$\text{Test error} = \frac1{m_{test}}\sum_{i=1}^{m_{test}}err\left(h_\theta(x_{test}^{(i)}),y_{test}^{(i)}\right)\<br>$$</p>
<h3 id="6-1-3_Model_Selection_and_Train/Validation/Test_Sets">6.1.3 Model Selection and Train/Validation/Test Sets</h3><p><strong>Overfitting example</strong></p>
<p>Once parameters $\theta_0,\theta_1,&#x2026;,\theta_4$ were fit to some set of data (traning set), the error of the parameters as measured on that data (the traing error $J(\theta)$) is likely to be lower than the actual generalization error.</p>
<p><strong>Model selection</strong></p>
<ol>
<li>$h_\theta(x) = \theta_0+\theta_1x$</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+\theta_2x^2$</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+&#x2026;+\theta_3x^2$<br>&#x2026;</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+&#x2026;+\theta_10x^10$</li>
</ol>
<p>Assume a new parameter $d$ = degree of polynomial. </p>
<p>Test dataset cost functions: $J_{test}(\theta_j)$ ($j$ is from 1 to $d$)</p>
<p>Problem: degree of polynomial is chosen based on the test dataset, therefore cannot guarantee the generalization ability to further data. </p>
<p><strong>Solution</strong>: divide the original dataset to a training set, a cross validation set (CV), and a test set. </p>
<p><strong>Train/validation/test error</strong></p>
<p>Use the CV set to select the model. Then estimate generalization error $J_{test}(\theta)$</p>
<h2 id="6-2_Bias_vs-_Variance">6.2 Bias vs. Variance</h2><h3 id="6-2-1_Diagnosing_Bias_vs-_Variance">6.2.1 Diagnosing Bias vs. Variance</h3><p>High bias - Underfit<br>High variance - Overfit</p>
<p>Training error: </p>
<p>$$J_{train}(\theta)=\frac1{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2$$</p>
<p>Cross validation error:<br>$$J_{cv}(\theta)=\frac1{2m_{cv}}\sum_{i=1}^{m_{cv}}\left(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)}\right)^2$$</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-01.png" alt=""></p>
<h3 id="6-2-2_Regularization_and_Bias/Variance">6.2.2 Regularization and Bias/Variance</h3><p><strong>Linear regression with regularization</strong></p>
<p>Large $\lambda$: high bias, underfit</p>
<p>Small $\lambda$: high variance, overfit</p>
<p><strong>Choosing the regularization parameter $\lambda$</strong></p>
<ul>
<li><p>have some range of $\lambda$ values: e.g. [0,0.01,0.02,0.04,0.08&#x2026;10]</p>
</li>
<li><p>calculate $\min J(\theta)$ for each $\lambda$ -&gt; $J_{cv}(\theta^{(?)})$</p>
</li>
<li><p>pick the lowest $J_{cv}(\theta^{(?)})$ $\theta^{(5)}$. Test error: $J_{test}(\theta^{(5)})$</p>
</li>
<li><p>Plot $J_{train}(\theta)$ and $J_{cv}(\theta)$ v.s. $\lambda$</p>
</li>
</ul>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-02.png" alt=""></p>
<h3 id="6-2-3_Learning_Curves">6.2.3 Learning Curves</h3><p>&#x589E;&#x52A0;&#x6837;&#x672C;&#x6570;&#x662F;&#x5426;&#x80FD;&#x51CF;&#x5C11;&#x8BEF;&#x5DEE;&#xFF1F;</p>
<p>Learning curves: plot error v.s. m (training set size)</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-03.png" alt=""></p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-04.png" alt=""></p>
<p>High bias:</p>
<p>If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much.</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-05.png" alt=""></p>
<p>High variance:</p>
<p>If a learning algorithm is suffering from high variance, getting more traning data is likely to help.</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png" alt=""></p>
<h3 id="6-2-4_Deciding_What_to_Do_Next_Revisited">6.2.4 Deciding What to Do Next Revisited</h3><p><strong>Debugging a learning algorithm</strong></p>
<p>Suppose you have implemented regularized linear regression to predict housing prices. </p>
<p>However, when you test your hypothesis on a new set of hourses, you find that it makes unacceptably large errors in its predictions. What should you try next?</p>
<ul>
<li>Get more training examples -&gt; _fixes high variance_</li>
<li>Try smaller sets of features -&gt; _fixes high variance_</li>
<li>Try getting additional features -&gt; _fixes high bias_</li>
<li>Try adding polynomial features $(x_1^2, x_2^2, x_1x_2, \text{etc})$ -&gt; _fixes high bias_</li>
<li>Try decreasing $\lambda$ -&gt; _fixes high bias_</li>
<li>Try increasing $\lambda$ -&gt; _fixes high variance_</li>
</ul>
<p><strong>Neural networks and overfitting</strong></p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png" alt=""></p>
<p>Using a single hidden layer is a reasonable default. But if you want to choose the number of hidden layers, one other thing you can try is find yourself a training cross-validation, and test set split and try training neural networks with one hidden layer or two hidden layers or three hidden layers and see which of those neural networks performs best on the cross-validation sets. </p>
<h2 id="6-3_Building_a_Spam_Classifier">6.3 Building a Spam Classifier</h2><h3 id="6-3-1_Prioritizing_What_to_Work_on">6.3.1 Prioritizing What to Work on</h3><h3 id="6-3-2_Error_Analysis">6.3.2 Error Analysis</h3><h2 id="6-4_Handling_Skewed_Data">6.4 Handling Skewed Data</h2><p>Cancer classification example<br>1% error on test set (99% correct)</p>
<h3 id="Error_Metrics_for_Skewed_Classes">Error Metrics for Skewed Classes</h3><h3 id="Trading_Off_Precision_and_Recall">Trading Off Precision and Recall</h3><p>Logistic regression:<br>Predict 1 if<br>Predict 0 if<br>Suppose we want to predict y = 1 only if very confident</p>
<p>-&gt; Higher precision, lower recall.</p>
<p>Suppose we want to avoid missing too many cases of cancer (avoid false negatives).</p>
<p>-&gt; higher recall, lower precision</p>
<p><strong>$F_1$ Score (F score)</strong></p>
<p>How to compare precision/recall numbers?</p>
<p>The average of P and R is not a good indicator</p>
<p>$F_1$ score: $2\frac{PR}{P+R}$</p>
<h2 id="6-5_Using_Large_Data_Sets">6.5 Using Large Data Sets</h2><h3 id="Designing_a_high_accuracy_learning_system">Designing a high accuracy learning system</h3><p>e.g. Classify between confusable words. {to,two,too},{then,than}</p>
<p>Algorithms:</p>
<ul>
<li>Perceptron (Logistic regression)</li>
<li>Winnow</li>
<li>Memory-based</li>
<li>Naive Bayes</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="6-_Machine_Learning_Application_Advice_and_System_Design">6. Machine Learning Application Advice and System Design</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5E94;&#x7528;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x4E8B;&#x9879;&#x4EE5;&#x53CA;&#x7CFB;&#x7EDF;&#x8BBE;&#x8BA1;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Learning Curves" scheme="http://tech.liuxiaozhen.com/tags/Learning-Curves/"/>
    
      <category term="Machine Learning" scheme="http://tech.liuxiaozhen.com/tags/Machine-Learning/"/>
    
      <category term="Model Selection" scheme="http://tech.liuxiaozhen.com/tags/Model-Selection/"/>
    
      <category term="Overfitting" scheme="http://tech.liuxiaozhen.com/tags/Overfitting/"/>
    
      <category term="Precision" scheme="http://tech.liuxiaozhen.com/tags/Precision/"/>
    
      <category term="Recall" scheme="http://tech.liuxiaozhen.com/tags/Recall/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Machine Learning By Stanford University Week 5]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/06/12/Machine-Learning-W5/"/>
    <id>http://tech.liuxiaozhen.com/2016/06/12/Machine-Learning-W5/</id>
    <published>2016-06-12T14:49:53.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<h1 id="5-_Neural_Networks:_Learning">5. Neural Networks: Learning</h1><p>&#x672C;&#x8BFE;&#x56DE;&#x987E;&#x4E86;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x6A21;&#x578B;&#x63CF;&#x8FF0;&#xFF0C;&#x5E76;&#x4ECB;&#x7ECD;&#x4E86;BP&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x3001;&#x4EE3;&#x4EF7;&#x51FD;&#x6570;&#x8868;&#x8FBE;&#x5F0F;&#x3001;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x3001;&#x4EE5;&#x53CA;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 May session.</strong></p>
<h2 id="5-1_Neural_Networks_(Classification)">5.1 Neural Networks (Classification)</h2><p>Training set $\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),&#x2026;,(x^{(m)},y^{(m)})\}$</p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-01.png" alt=""></p>
<p>L = total no. of layers in network. (Here L = 4)</p>
<p>$s_l$ = no. of units (not counting bias unit) in layer $l$</p>
<p>(Here $s_1 = 3$, $s_2 = 5$,$s_4 = s_l =4$)</p>
<p>For binary classification, there is only 1 output unit; therefore $s_l = 1$. For multi-class classification (K classes), $s_l = K$. ($K\geq3$) </p>
<h3 id="5-1-1_Cost_functions_&#x4EE3;&#x4EF7;&#x51FD;&#x6570;">5.1.1 Cost functions &#x4EE3;&#x4EF7;&#x51FD;&#x6570;</h3><p><strong>a) Logistic regression</strong><br>$$J(\theta)=-\frac1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta(x^{(i)})+(1-y^{(i)})\log\left(1-h_\theta(x^{(i)})\right)\right] + \frac\lambda{2m}\sum_{j=1}^n\theta_j^2$$</p>
<p><strong>b) Neural network</strong><br>$$h_\Theta(x)\in \mathbb{R}^K\qquad(h_\Theta(x))_i = i^{th}  \space\mathrm{output}$$</p>
<p>$$<br>J(\Theta)=-\frac1m\left[\sum_{i=1}^m\sum_{k=1}^Ky_k^{(i)}\log(h_\Theta(x^{(i)}))_k+(1-y_k^{(i)})\log(1-(h_\Theta(x^{(i)}))_k)\right]+\frac\lambda{2m}\sum_{l=1}^{L-1}\sum_{i=1}^{s_l}\sum_{j=1}^{s_l+1}(\Theta_{ji}^{(l)})^2<br>$$</p>
<h3 id="5-1-2_Backpropagation_Algorithm">5.1.2 Backpropagation Algorithm</h3><p>&#x4E3A;&#x4E86;&#x6700;&#x5C0F;&#x5316;&#x8BEF;&#x5DEE;&#xFF0C;&#x9700;&#x8981;&#x627E;&#x5230;&#x4F7F;&#x4EE3;&#x4EF7;&#x51FD;&#x6570; $j(\theta)$ &#x6700;&#x5C0F;&#x7684; $\theta$. &#x56E0;&#x6B64;&#xFF0C;&#x9700;&#x8981;&#x5728;&#x4EE3;&#x7801;&#x4E2D;&#x8BA1;&#x7B97; $j(\theta)$ &#x53CA;&#x5176;&#x5FAE;&#x5206;&#x5F0F;&#x3002;</p>
<p><strong>a) Gradient Computation</strong></p>
<p>&#x8003;&#x8651;&#x6700;&#x7B80;&#x5355;&#x60C5;&#x51B5;&#xFF0C;&#x4EC5;&#x6709;&#x4E00;&#x4E2A;&#x8BAD;&#x7EC3;&#x6837;&#x672C;&#xFF1A;<br>Given one training example ($x,y$):</p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-02.png" alt=""></p>
<p><strong>b) Forward propagation&#x8BA1;&#x7B97;&#x6B65;&#x9AA4;</strong></p>
<ul>
<li>$a^{(1)} = x$</li>
<li>$z^{(2)} = \Theta^{(1)}a^{(1)}$</li>
<li>$a^{(2)}=g(z^{(2)})\quad(\mathrm{add}\space a_0^{(2)})$</li>
<li>$z^{(3)} = \Theta^{(2)}a^{(2)}$</li>
<li>$a^{(3)}=g(z^{(3)})\quad(\mathrm{add}\space a_0^{(3)})$</li>
<li>$z^{(4)} = \Theta^{(3)}a^{(3)}$</li>
<li>$a^{(4)}=h_\Theta(x)=g(z^{(4)})$</li>
</ul>
<p><strong>c) Backpropagation algorithm</strong></p>
<p>Intuition: $\delta_j^{(l)} = $ &#x201C;error&#x201D; of node $j$ in layer $l$.</p>
<p>&#x8BBE; $\delta_j^{(l)}$ &#x4E3A;&#x7B2C; $l$ &#x5C42;&#x7B2C; $j$ &#x4E2A;&#x795E;&#x7ECF;&#x5143;&#x7684;&#x8BEF;&#x5DEE;&#x503C;&#x3002;</p>
<p>For each output unit (layer L = 4)</p>
<ul>
<li>$\delta_j^{(4)}=a_j^{(4)}-y_j=(h_\Theta(x))_j-y_j$</li>
</ul>
<p>Vector form:</p>
<ul>
<li><p>$\delta^{(4)}=a^{(4)}-y$</p>
</li>
<li><p>$\delta^{(3)}=(\Theta^{(3)})^T\delta^{(4)}._g&#x2019;(z^{(3)}),\quad g&#x2019;(z^{(3)})=a^{(3)}._(1-a^{(3)})$</p>
</li>
<li><p>$\delta^{(2)}=(\Theta^{(2)})^T\delta^{(3)}._g&#x2019;(z^{(2)}),\quad g&#x2019;(z^{(2)})=a^{(2)}._(1-a^{(2)})$</p>
</li>
<li><p>(There is No $\delta^{(1)}$!)</p>
</li>
</ul>
<p><strong>d) Backpropagation implementation</strong></p>
<ul>
<li><p>Set $\Delta_{ij}^{(l)}=0$ (for all $l,i,j$).</p>
</li>
<li><p>For $i = 1$ to $m$</p>
<ul>
<li>&#x8BBE;&#x7F6E;&#x521D;&#x59CB;&#x6FC0;&#x6D3B;&#x503C; Set $a^{(1)}=x^{(i)}$</li>
<li>&#x6B63;&#x5411;&#x8BA1;&#x7B97;&#x5404;&#x5C42;&#x6FC0;&#x6D3B;&#x503C; Perform forward propagation to compute $a^{(l)}$ for $l=2,3,&#x2026;,L$</li>
<li>&#x7528;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#xFF0C;&#x8BA1;&#x7B97;&#x6700;&#x7EC8;&#x5C42;&#x8BEF;&#x5DEE; Using $y^{(i)}$, compute $\delta^{(L)}=a^{(L)}-y^{(i)}$</li>
<li>&#x53CD;&#x5411;&#x8BA1;&#x7B97;&#x5176;&#x4ED6;&#x5C42;&#x7684;&#x8BEF;&#x5DEE; Compute $\delta^{(L-1)}, \delta^{(L-2)},\delta^{(2)}$</li>
<li><p>$\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$   </p>
<p> Here, vector form: </p>
<p> $\Delta^{(l)}:=\Delta^{(l)}+\delta^{(l+1)}(a^{(l)})^T$  </p>
</li>
</ul>
</li>
</ul>
<p>  $$\frac\partial{\partial\Theta_{ij}^{(l)}}J(\Theta)=D_{ij}^{(l)}$$</p>
<ul>
<li>&#x4EE3;&#x4EF7;&#x51FD;&#x6570;&#x7684;&#x5FAE;&#x5206;&#x5F0F;<br>$D_{ij}^{(l)}:=\frac1m\Delta_{ij}^{(l)}+\lambda\Delta_{ij}^{(l)}$ if $j\neq0$<br>$D_{ij}^{(l)}:= \frac1m\Delta_{ij}^{(l)}\qquad$ if $j=0$</li>
</ul>
<h3 id="5-1-3_Backpropagation_Intuition">5.1.3 Backpropagation Intuition</h3><p><strong>a) Forward Propagation</strong></p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-03.png" alt=""></p>
<p><strong>b) What is backpropagation doing</strong></p>
<p>Focosing on a single example $x^{(i)}, y^{(i)}$, the case of 1 output unit, and ignoring regularization ($\lambda=0$),<br>$$<br>cost(i)=y^{(i)}\log h_\Theta(x^{(i)})+(1-y^{(i)})\log h_\Theta(x^{(i)})<br>$$</p>
<p>(Think of $cost(i)\approx(h_\Theta(x^{(i)})-y^{(i)})^2$)</p>
<p>i.e. how well is the network doing on example i?</p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-04.png" alt=""></p>
<h2 id="5-2_Backpropagation_Implementation_Notes">5.2 Backpropagation Implementation Notes</h2><h3 id="5-2-1_Unrolling_Parameters">5.2.1 Unrolling Parameters</h3><p><strong>a) Advanced Optimization</strong></p>
<p><code>function [jVal, gradient] = costFunction(theta)</code><br>&#x2026;<br><code>optTheta = fminunc(@costFunction, initialTheta, options)</code></p>
<p>Neutal Network(L=4):<br>$\Theta^{(1)},\Theta^{(2)},\Theta^{(3)}$ - matrices(<code>Theta1, Theta2, Theta3</code>)<br>$D^{(1)},D^{(2)},D^{(3)}$ - matrices (<code>D1, D2, D3</code>)</p>
<p>&#x201C;Unroll&#x201D; into vectors</p>
<p><strong>b) Example</strong></p>
<p>$s_1 = 10,s_2 = 10, s_3=1$</p>
<p>$\Theta^{(1)}\in \mathbb{R}^{10\times11}, \Theta^{(2)}\in \mathbb{R}^{10\times11},\Theta^{(3)}\in \mathbb{R}^{1\times11}$</p>
<p>$D^{(1)}\in \mathbb{R}^{10\times11}, D^{(2)}\in \mathbb{R}^{10\times11},D^{(3)}\in \mathbb{R}^{1\times11}$</p>
<p><code>thetaVec = [ Theta1(:); THeta2(:); Theta3(:)];</code><br><code>DVec = [D1(:); D2(:); D3(:)];</code></p>
<p><code>Theta1 = reshape(thetaVec(1:110),10,11);</code><br><code>Theta2 = reshape(thetaVec(111:220),10,11);</code><br><code>Theta3 = reshape(thetaVec(221:231),1,11);</code></p>
<p><strong>c) Learning Algorithm</strong></p>
<ul>
<li><p>Have initial parameters $\Theta^{(1)},\Theta^{(2)},\Theta^{(3)}$.</p>
</li>
<li><p>Unroll to get <code>initialTheta</code> to pass to <code>fminunc(@costFunction, initialTheta, options)</code></p>
</li>
<li><p><code>function [jval, gradientVec] = costFunction(thetaVec)</code></p>
</li>
<li><p>From <code>thetaVec</code>, get $\Theta^{(1)},\Theta^{(2)},\Theta^{(3)}$.</p>
</li>
<li><p>Use forward prop/back prop to compute $D^{(1)},D^{(2)},D^{(3)}$ and $J(\Theta)$.</p>
</li>
<li>Unroll $D^{(1)},D^{(2)},D^{(3)}$ to get <code>gradientVec</code>.</li>
</ul>
<h3 id="5-2-2_Gradient_Checking">5.2.2 Gradient Checking</h3><p>In order to verify that the neural network algorithm is working properly, one needs to do gradient checking. </p>
<p><strong>a) Numerial estimation of gradients</strong></p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-05.png" alt=""></p>
<p>Implement:<br><code>gradApprox = (J(theta + EPASILON) - J(theta - EPSILON))/(2*EPSILON)</code></p>
<p><strong>b) Parameter vector $\theta$</strong></p>
<p><img src="/2016/06/12/Machine-Learning-W5/Coursera-ml-w5-06.png" alt=""></p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">i</span> = <span class="number">1</span>:n,</span><br><span class="line">	thetaPlus = theta;</span><br><span class="line">	thetaPlus(<span class="built_in">i</span>) = thetaPlus(<span class="built_in">i</span>) + EPSILON;</span><br><span class="line">	thetaMinus = theta;</span><br><span class="line">	thetaMinus(<span class="built_in">i</span>) = thetaMinus(<span class="built_in">i</span>) - EPSILON;</span><br><span class="line">	gradApprox(<span class="built_in">i</span>) = (J(thetaPlus) - J(thetaMinus))/(<span class="number">2</span>*EPSILON);</span><br><span class="line"><span class="keyword">end</span>;</span><br></pre></td></tr></table></figure>
<p>Check that <code>gradApprox</code> $\approx$ <code>DVec</code> </p>
<p><strong>c) Implementation Note:</strong></p>
<ul>
<li>Implement backprop to compute <code>DVec</code> (unrolled $D^{(1)},D^{(2)},D^{(3)}$).</li>
<li>Implement numerial gradient check to compute <code>gradApprox</code>.</li>
<li>Make sure they give similar values.</li>
<li>Turn off gradient checking. Using backprop code for learning.</li>
</ul>
<p><strong>Important:</strong></p>
<ul>
<li>Be sure to disable your gradient cheking code before training your classifier. If you run numeiral gradient computation on every iteration of gradient descent (or in the inner loop of <code>costFunction(...)</code>) your code will be very slow.</li>
</ul>
<h3 id="5-2-3_Random_Initialization">5.2.3 Random Initialization</h3><p>Need initial value for $\Theta\$</p>
<ul>
<li>Zero initialization. <ul>
<li>$\Theta_{ij}^{(l)} = 0$ for all $i,j,l$</li>
<li>will cause the problem of symmetric ways: </li>
</ul>
</li>
<li>Random initialization: Symmetry breaking. <ul>
<li>initialize each $\Theta_{ij}^{(l)}$ to a random value in $[-\epsilon,\epsilon]$</li>
<li>E.g.<br><code>Theta1 = rand(10,11) * (2*INIT_EPSILON) - INIT_EPSILON;</code><br><code>Theta2 = rand(1,11) * (2*INIT_EPSILON) - INIT_EPSILON;</code></li>
</ul>
</li>
</ul>
<h2 id="5-3_Putting_It_Together">5.3 Putting It Together</h2><h3 id="5-3-1_Training_a_neural_network">5.3.1 Training a neural network</h3><ul>
<li>pick a network architecture (connectivity pattern between neurons)</li>
<li>No. of input units: Dimension of features </li>
<li>No. output units: Number of classes</li>
<li>Reasonable default: 1 hidden layer, or if &gt;1 hidden layer, have same no. of hidden uints in every layer (usually the more the better, but will be more computational expensive). </li>
</ul>
<h3 id="5-3-2_Steps_of_training_a_neural_network">5.3.2 Steps of training a neural network</h3><ol>
<li>Randomly initialize weights</li>
<li>Implement forward propagation to get $h_\Theta(x^{(i)})$ for any $x^{(i)}$</li>
<li>Implement code to compute cost function $J(\Theta)$</li>
<li>Implement backprop to compute partial derivatives $\frac{\partial}{\partial\Theta_{jk}^{(l)}}J(\Theta)$</li>
<li>Use gradient checking to compare $\frac{\partial}{\partial\Theta_{jk}^{(l)}}J(\Theta)$ computed using backpropagation v.s. using numerical estimate of gradient of $J(\Theta)$. Then disable gradient checking code.</li>
<li>Use gradient descent or advanced optimization method with backpropagation to try to minimize $J(\theta)$ as a function of parameters $\Theta$</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="5-_Neural_Networks:_Learning">5. Neural Networks: Learning</h1><p>&#x672C;&#x8BFE;&#x56DE;&#x987E;&#x4E86;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x6A21;&#x578B;&#x63CF;&#x8FF0;&#xFF0C;&#x5E76;&#x4ECB;&#x7ECD;&#x4E86;BP&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7684;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x3001;&#x4EE3;&#x4EF7;&#x51FD;&#x6570;&#x8868;&#x8FBE;&#x5F0F;&#x3001;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x7B97;&#x6CD5;&#x3001;&#x4EE5;&#x53CA;&#x968F;&#x673A;&#x521D;&#x59CB;&#x5316;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Machine Learning" scheme="http://tech.liuxiaozhen.com/tags/Machine-Learning/"/>
    
      <category term="Neural Networks" scheme="http://tech.liuxiaozhen.com/tags/Neural-Networks/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Machine Learning By Stanford University Week 3]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/05/14/Machine-Learning-W3/"/>
    <id>http://tech.liuxiaozhen.com/2016/05/14/Machine-Learning-W3/</id>
    <published>2016-05-14T15:22:21.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<h1 id="3-_Logistic_Regression_and_Regularization">3. Logistic Regression and Regularization</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x5206;&#x6790;&#xFF08;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x6C42;&#x89E3;&#xFF09;&#x53CA;&#x6B63;&#x5219;&#x5316;&#x65B9;&#x6CD5;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 March session.</strong></p>
<h2 id="3-1_Logistic_Regression">3.1 Logistic Regression</h2><h3 id="3-1-1_Classification_Problems_and_Logistic_Regression_Model">3.1.1 Classification Problems and Logistic Regression Model</h3><p><strong>a) Classification Problems</strong></p>
<ul>
<li>Email&#xFF1A; spam/not spam</li>
<li>Online transactions: froudulent or not</li>
<li>Tumor: malignant/benign</li>
</ul>
<p>$y\in{0,1}$</p>
<ul>
<li>0: &#x201C;Negative Class&#x201D;</li>
<li>1: &#x201C;Positive Class&#x201D;</li>
</ul>
<p>Use threshold classifier output $h_\theta(x)$ at 0.5</p>
<ul>
<li>If $h_\theta(x) \geq 0.5$, predict &#x201C;y=1&#x201D;</li>
<li>If $h_\theta(x) &lt; 0.5$, predict &#x201C;y=0&#x201D; </li>
</ul>
<p><strong>b) Logistic Regression Model</strong><br>Want $0\leq h_\theta(x) \leq 1$</p>
<p>$h_\theta(x) = g(\theta^Tx)$<br>The sigmoid function: $g(z) = \frac 1{1+e^{-z}}$<br>$$h_\theta(x) =\frac 1{1+e^{-\theta^Tx}}$$</p>
<p>whenever $z \geq 0$, or $\theta^Tx \geq 0$,y =1</p>
<h3 id="3-1-2_Decision_Boundary">3.1.2 Decision Boundary</h3><p><strong>a) Decision Boundary</strong></p>
<p>$h_\theta(x) = g(\theta_0+\theta_1x_1+\theta_2x_2)$</p>
<p><strong>b) Non-linear decision boundaries</strong></p>
<p>$h_\theta(x) = g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)$</p>
<p>Predict &#x201C;y=1&#x201D; if $-1+x_1^2+x_2^2 \geq 0$</p>
<h2 id="3-1-3_Cost_Function">3.1.3 Cost Function</h2><p>Logistic regression:</p>
<p>$$\text{Cost}(h_\theta(x^{(i)}),y^{(i)}) = \frac12\left(h_\theta(x^{(i)})-y^{(i)}\right)^2$$</p>
<p>&#x201C;non-convex&#x201D; v.s. &#x201C;convex&#x201D;</p>
<p>$$\text{Cost}(h_\theta(x),y)=\begin{cases}\quad-\log(h_\theta(x))<br>\quad\text{if } y = 1\<br>-\log(1-h_\theta(x))\quad\text{if }y =0<br>\end{cases}$$</p>
<p>Cost = 0 if y=1, $h_\theta(x)=1$<br>But as $h_\theta(x)\rightarrow 0$, Cost $\rightarrow \infty$</p>
<p>More compact way:</p>
<p>$\text{Cost}(h_\theta(x),y)=-y\log\left(h_\theta(x)\right)-(1-y)\log\left(1-h_\theta(x)\right)<br>$</p>
<p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]$$</p>
<p>To fit parameters $\theta$:<br>$\min_\theta J (\theta)$</p>
<p>Repeat {</p>
<p>$$\theta_j:=\theta_j-\alpha\sum_{i=1}^m \left( h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(j)}$$</p>
<p>}</p>
<p>Algorithm looks identical to linear regression!</p>
<h3 id="3-1-4_Optimization_algorithm">3.1.4 Optimization algorithm</h3><ul>
<li>Gradient descent</li>
<li>Conjugate gradient</li>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
<p>Advantages:</p>
<ul>
<li><p>No need to manually pick $\alpha$</p>
</li>
<li><p>Often faster than gradient descent</p>
</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>More complex</li>
</ul>
<h3 id="3-1-5_Multiclass_Classification">3.1.5 Multiclass Classification</h3><p><strong>a) Problem examples</strong></p>
<ul>
<li>Email foldering/tagging: work, friends, family, hobby</li>
<li>Medical diagrams: not ill, cold, flu</li>
<li>Weather: sunny, cloudy, rain, snow</li>
</ul>
<p><strong>b) One-vs-all (one-vs-rest)</strong><br><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-01.png" alt=""></p>
<p>&#x5C06;&#x9700;&#x8981;&#x5206;&#x4E3A;N&#x7C7B;&#x7684;&#x6570;&#x636E;&#x62C6;&#x5206;&#x6210; N&#x4E2A;0/1&#xFF08;&#x662F;&#xFF0F;&#x5426;&#xFF09;&#x95EE;&#x9898;&#x3002;</p>
<p>Train a logistic regression classifier $h_\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$.</p>
<p>On a new input $x$, to make a prediction, pick the class $i$ that maximizes $\max h_\theta^{(i)}(x)$.</p>
<h2 id="3-2_Regularization_&#x6B63;&#x5219;&#x5316;">3.2 Regularization &#x6B63;&#x5219;&#x5316;</h2><h3 id="3-2-1_Overfitting_Problems_&#x8FC7;&#x62DF;&#x5408;&#x95EE;&#x9898;">3.2.1 Overfitting Problems &#x8FC7;&#x62DF;&#x5408;&#x95EE;&#x9898;</h3><p><strong>a) Example: Linear Regression (housing prices)</strong></p>
<p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-02.png" alt=""></p>
<p>&#x5BF9;&#x4E8E;&#x623F;&#x5C4B;&#x4EF7;&#x683C;&#x7684;&#x4E09;&#x79CD;&#x62DF;&#x5408;&#x66F2;&#x7EBF;&#x4E0E;&#x5B9E;&#x9645;&#x6570;&#x636E;&#x7684;&#x7B26;&#x5408;&#x60C5;&#x51B5;&#xFF1A;</p>
<ul>
<li>&#x4E00;&#x5143;&#x7EBF;&#x6027;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;underfit, high bias</li>
<li>&#x4E00;&#x5143;&#x4E8C;&#x6B21;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;just right</li>
<li>&#x4E00;&#x5143;&#x56DB;&#x6B21;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;overfit, high variance</li>
</ul>
<p><strong>Overfitting:</strong> If we have too many features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples (predict prices on new examples).</p>
<p><strong>b) Example: Logistic Regression</strong><br><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-03.png" alt=""></p>
<p><strong>Addressing overfitting:</strong></p>
<ul>
<li>Reduce number of features:<ul>
<li>Manually select which features to keep</li>
<li>Model selection algorithm (later in course)</li>
</ul>
</li>
<li>Regularization:<ul>
<li>Keep all the features, but reduce magnitude/values of parameters $\theta_j$.</li>
<li>Works well when we have a lot of features, each of which contributes a bit to predicting $y$.</li>
</ul>
</li>
</ul>
<h3 id="3-2-2_Cost_Function">3.2.2 Cost Function</h3><p><strong>a) Intuition</strong></p>
<p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-04.png" alt=""></p>
<p>Suppose we penalize and make $\theta_3,\theta_4$ really small.</p>
<p>$$\min_\theta\frac1{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2 +1000\theta_3^2+1000\theta_4^2$$</p>
<p>$\theta_3,\theta_4$ will be very small.</p>
<p><strong>b) Regularization</strong></p>
<p>Small values for parameters $\theta_0, \theta_1, &#x2026;, \theta_n$</p>
<ul>
<li>&#x201C;Simpler&#x201D; hypothesis</li>
<li>Less prone to overfitting</li>
</ul>
<p><strong>Cost Function</strong><br>$$<br>J(\theta) = \frac1{2m}\left[\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{j=1}^n\theta_j^2\right]<br>$$</p>
<p>$\theta_0$ is excluded as a convention.</p>
<p>If $\lambda$ is too large, we might have underfitting problems. </p>
<h3 id="3-2-3_Regularized_Linear_Regression">3.2.3 Regularized Linear Regression</h3><p><strong>a) Gradient descent</strong></p>
<p>Repeat {<br>$$\theta_0:=\theta_0-\alpha\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_0^{(i)}$$</p>
<p>$$\theta_j:=\theta_j-\alpha\left[\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}+\frac{\lambda}m\theta_j\right]$$</p>
<p>}</p>
<p>$$<br>\theta_j := \theta_j(1-\alpha\frac{\lambda}m)-\alpha\frac1m\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}<br>$$</p>
<p>$1-\alpha\frac{\lambda}m&lt;1$. Therefore, use $\theta_j^2$ as an approximation</p>
<p><strong>b) Normal equation</strong><br>$$<br>X = \begin{bmatrix}<br>(x^{(1)})^T\<br>&#x2026;\<br>(x^{(m)})^T\<br>\end{bmatrix}$$</p>
<p>$$<br>y = \begin{bmatrix}<br>(y^{(1)})^T\<br>&#x2026;\<br>(y^{(m)})^T\<br>\end{bmatrix}$$</p>
<p>To minimize $J(\theta)$</p>
<p>$$\theta = \left(X^TX+\lambda \begin{bmatrix}<br>0&amp;0&amp;0&amp;&#x2026;&amp;0\<br>0&amp;1&amp;0&amp;&#x2026;&amp;0\<br>0&amp;0&amp;1&amp;&#x2026;&amp;0\<br>&#x2026;&amp;&#x2026;&amp;&#x2026;&amp;1&amp;&#x2026;\<br>0&amp;0&amp;0&amp;&#x2026;&amp;1\<br>\end{bmatrix}\right)^{-1}X^Ty$$</p>
<p><strong>c) Non-invertibility (optional/advanced)</strong></p>
<p>Suppose $m\leq n$,<br>(where m: number of examples; n: number of features)</p>
<p>$$\theta = (X^TX)^{-1}X^Ty$$</p>
<p>$X^TX$ is non-invertible/singular. In Octave/MATLAB, use <code>pinv</code> instead of <code>inv</code>.</p>
<p>If $\lambda \gt 0,$<br>$$<br>\theta = \left(X^TX+\lambda \begin{bmatrix}<br>0&amp;0&amp;0&amp;&#x2026;&amp;0\<br>0&amp;1&amp;0&amp;&#x2026;&amp;0\<br>0&amp;0&amp;1&amp;&#x2026;&amp;0\<br>&#x2026;&amp;&#x2026;&amp;&#x2026;&amp;1&amp;&#x2026;\<br>0&amp;0&amp;0&amp;&#x2026;&amp;1\<br>\end{bmatrix}\right)^{-1}X^Ty<br>$$</p>
<h3 id="3-2-4_Regularized_Logistic_Regression">3.2.4 Regularized Logistic Regression</h3><p><strong>a) Cost function:</strong></p>
<p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$$</p>
<p><strong>b) Gradient descent</strong></p>
<p>Repeat {<br>$$\theta_0:=\theta_0-\alpha\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_0^{(i)}$$</p>
<p>$$\theta_j:=\theta_j-\alpha\left[\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}+\frac{\lambda}m\theta_j\right]$$</p>
<p>}</p>
<p>where $h_\theta(x)=\frac1{1+e^{-\theta^TX}}$</p>
<p>**c) Advaced optimization</p>
<p><code>function [jVal, gradient] = costFunction(theta)</code></p>
<p><code>jVal =</code>[code to compute $J(\theta)$];</p>
<p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$$</p>
<p><code>gradient(1)</code> = [code to compute $\frac\partial{\partial\theta_0}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_0^{(i)}$$</p>
<p><code>gradient(2)</code> = [code to compute $\frac\partial{\partial\theta_1}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_1^{(i)}&#xFF0B;\frac\lambda m\theta_1$$</p>
<p><code>gradient(3)</code> = [code to compute $\frac\partial{\partial\theta_2}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_2^{(i)}&#xFF0B;\frac\lambda m\theta_2$$<br>&#x2026;</p>
<p><code>gradient(n+1)</code> = [code to compute $\frac\partial{\partial\theta_n}J(\theta)$];</p>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="3-_Logistic_Regression_and_Regularization">3. Logistic Regression and Regularization</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x5206;&#x6790;&#xFF08;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x6C42;&#x89E3;&#xFF09;&#x53CA;&#x6B63;&#x5219;&#x5316;&#x65B9;&#x6CD5;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Logistic Regression" scheme="http://tech.liuxiaozhen.com/tags/Logistic-Regression/"/>
    
      <category term="Machine Learning" scheme="http://tech.liuxiaozhen.com/tags/Machine-Learning/"/>
    
      <category term="Regularization" scheme="http://tech.liuxiaozhen.com/tags/Regularization/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据分析师养成计划（2）]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/04/28/udacity-data-analyst-nanodegree-1/"/>
    <id>http://tech.liuxiaozhen.com/2016/04/28/udacity-data-analyst-nanodegree-1/</id>
    <published>2016-04-28T08:59:53.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>&#x8BB0;&#x5F55;Udacity&#x4E0A;&#x7684;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;Nanodegree&#x7684;&#x7B2C;&#x4E00;&#x90E8;&#x5206;&#x8BFE;&#x7A0B;&#x5185;&#x5BB9;&#xFF0C;&#x5305;&#x62EC;&#x6700;&#x57FA;&#x672C;&#x7684;&#x7EDF;&#x8BA1;&#x5B66;&#x77E5;&#x8BC6;&#x3002;</p>
<a id="more"></a>
<p><strong>&#x672C;&#x6587;&#x662F;&#x5B66;&#x4E60;Udacity&#x4E0A;&#x7684;Nanodegree: Data Analyst&#x7684;&#x8BB0;&#x5F55;&#xFF0C;&#x81EA;2016&#x5E74;4&#x6708;24&#x65E5;&#x59CB;&#x3002;</strong></p>
<p><strong>&#x672C;&#x7CFB;&#x5217;&#x5168;&#x90E8;&#x6587;&#x7AE0;&#x89C1;<a href="http://tech.liuxiaozhen.com/tags/Data-Analyst/" target="_blank" rel="external">Tag: Data Analyst</a> &#x3002;</strong></p>
<h1 id="Project_1">Project 1</h1><h2 id="Lesson_1_Intro_to_Research_Methods">Lesson 1 Intro to Research Methods</h2><p>&#x8FD9;&#x8282;&#x8BFE;&#x8BB2;&#x600E;&#x4E48;&#x505A;&#x8C03;&#x67E5;&#x7814;&#x7A76;&#x3002;&#x5B9A;&#x6027;&#x5730;&#x8BB2;&#x4E86;&#x91C7;&#x6837;&#xFF0C;&#x968F;&#x673A;&#x6027;&#x3001;&#x53CC;&#x76F2;&#x5B9E;&#x9A8C;&#x3001;&#x76F8;&#x5173;&#x6027;&#x4E0E;&#x56E0;&#x679C;&#x6027;&#xFF0C;&#x6570;&#x636E;&#x9610;&#x91CA;&#x7B49;&#x3002;</p>
<p>&#x5173;&#x952E;&#x6982;&#x5FF5;&#xFF1A;</p>
<ul>
<li>Population &amp; Sample</li>
<li>Parameters &amp; Statistics</li>
<li>Sampling Error</li>
<li>Independent Variables, Dependent Variables, and Lurking Variables</li>
<li>Observations v.s. Experiments</li>
<li>&#x76F8;&#x5173;&#x6027;&#x4E0E;&#x56E0;&#x679C;&#x6027;</li>
<li>&#x53CC;&#x76F2;&#x5B9E;&#x9A8C;</li>
</ul>
<h2 id="Lesson_2:_Visualizing_Data">Lesson 2: Visualizing Data</h2><p>&#x8FD9;&#x8282;&#x8BFE;&#x8BB2;&#x5982;&#x4F55;&#x7528;&#x76F4;&#x65B9;&#x56FE;&#x6765;&#x5448;&#x73B0;&#x6570;&#x636E;&#x3002;</p>
<p>&#x5173;&#x952E;&#x6982;&#x5FF5;&#xFF1A;</p>
<ul>
<li>Frequency, Relative Frequency, Proportions and Percentages</li>
<li>Histogram: numerical values</li>
<li>Bar Graph: categories</li>
<li>Bin size</li>
<li>Skewed Distribution<ul>
<li>Positively skewed distribution: scores with the lowest frequencies are on the right side of the distribution</li>
<li>Negatively skewed distribution: scores with the highest frequencies are on the left side of the distribution</li>
</ul>
</li>
<li>Uniform, bimode and normal distrubution</li>
</ul>
<h2 id="Lesson_3:_Central_Tendancy">Lesson 3: Central Tendancy</h2><p>&#x8FD9;&#x8282;&#x8BFE;&#x4E3B;&#x8981;&#x8BB2;mode, mean, median&#x7684;&#x6982;&#x5FF5;&#xFF0C;&#x4EE5;&#x53CA;&#x5BF9;&#x4E8E;&#x4E0D;&#x540C;&#x7684;&#x5206;&#x5E03;&#xFF0C;&#x8FD9;&#x4E9B;&#x7279;&#x5F81;&#x503C;&#x6709;&#x4F55;&#x7279;&#x70B9;&#xFF0C;&#x53CD;&#x6620;&#x4E86;&#x4EC0;&#x4E48;&#x6837;&#x7684;&#x6027;&#x8D28;&#x3002;</p>
<h2 id="Lesson_4:_Variability">Lesson 4: Variability</h2><p>&#x8FD9;&#x8282;&#x8BFE;&#x8BB2;&#x4E86;variance&#x548C;standard deviation&#x5982;&#x4F55;&#x8BA1;&#x7B97;&#xFF0C;&#x4EE5;&#x53CA;normal distribution&#x7684;&#x4E00;&#x4E9B;&#x5C5E;&#x6027;&#x3002;</p>
<p>&#x76EE;&#x524D;&#x4E3A;&#x6B62;&#x8BFE;&#x7A0B;&#x90FD;&#x8FD8;&#x5F88;&#x57FA;&#x7840;&#xFF0C;&#x6682;&#x65F6;&#x4E0D;&#x4F1A;&#x6709;&#x4EC0;&#x4E48;&#x5927;&#x620F;&#x3002;&#x6211;&#x4EEC;&#x8FD8;&#x662F;&#x6765;&#x770B;&#x770B;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5427;~<br>&#xFF08;&#x5F85;&#x7EED;&#xFF09;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>&#x8BB0;&#x5F55;Udacity&#x4E0A;&#x7684;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;Nanodegree&#x7684;&#x7B2C;&#x4E00;&#x90E8;&#x5206;&#x8BFE;&#x7A0B;&#x5185;&#x5BB9;&#xFF0C;&#x5305;&#x62EC;&#x6700;&#x57FA;&#x672C;&#x7684;&#x7EDF;&#x8BA1;&#x5B66;&#x77E5;&#x8BC6;&#x3002;</p>]]>
    
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[数据分析师养成计划（1）]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/04/27/udacity-data-analyst-nanodegree-0/"/>
    <id>http://tech.liuxiaozhen.com/2016/04/27/udacity-data-analyst-nanodegree-0/</id>
    <published>2016-04-27T09:17:30.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>&#x4ECB;&#x7ECD;Udacity&#xFF08;&#x5728;&#x534E;&#x540D;&#x79F0;&#x201C;&#x4F18;&#x8FBE;&#x5B66;&#x57CE;&#x201D;&#xFF09;&#x7684;&#x201C;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x201D;&#x9879;&#x76EE;&#xFF0C;&#x53CA;&#x5176;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;&#x9879;&#x76EE;&#x7684;&#x57FA;&#x672C;&#x60C5;&#x51B5;&#x3002;</p>
<a id="more"></a>
<p><strong>&#x672C;&#x6587;&#x662F;&#x5B66;&#x4E60;Udacity&#x4E0A;&#x7684;Nanodegree: Data Analyst&#x7684;&#x8BB0;&#x5F55;&#xFF0C;&#x81EA;2016&#x5E74;4&#x6708;24&#x65E5;&#x59CB;&#x3002;</strong></p>
<p><strong>&#x672C;&#x7CFB;&#x5217;&#x5168;&#x90E8;&#x6587;&#x7AE0;&#x89C1;<a href="http://tech.liuxiaozhen.com/tags/Data-Analyst/" target="_blank" rel="external">Tag: Data Analyst</a> &#x3002;</strong></p>
<h1 id="&#x7B80;&#x4ECB;">&#x7B80;&#x4ECB;</h1><p>&#x5728;&#x7EBF;&#x5B66;&#x4E60;&#x5E73;&#x53F0;Udacity&#x53BB;&#x5E74;&#x521A;&#x521A;&#x5B8C;&#x6210;D&#x8F6E;&#x878D;&#x8D44;&#xFF0C;&#x4F30;&#x503C;&#x8D85;&#x8FC7;10&#x4EBF;&#x7F8E;&#x5143;&#xFF0C;&#x6210;&#x4E3A;&#x5728;&#x7EBF;&#x6559;&#x80B2;&#x7B2C;&#x4E00;&#x5BB6;&#x72EC;&#x89D2;&#x517D;&#x3002;&#x6211;&#x4ECE;2012&#x5E74;&#x5C31;&#x5F00;&#x59CB;&#x5173;&#x6CE8;&#x548C;&#x5B66;&#x4E60;Udacity&#x7684;&#x8BFE;&#x7A0B;&#x3002;&#x4ECA;&#x5E74;4&#x6708;&#xFF0C;Udacity&#x4EE5;&#x201C;&#x4F18;&#x8FBE;&#x5B66;&#x57CE;&#x201D;&#x4E3A;&#x540D;&#x5165;&#x534E;&#xFF0C;&#x4E00;&#x8FDB;&#x5165;&#x5C31;&#x8DDF;&#x6EF4;&#x6EF4;&#x3001;&#x4EAC;&#x4E1C;&#x3001;&#x65B0;&#x6D6A;&#x8FBE;&#x6210;&#x5408;&#x4F5C;&#x610F;&#x5411;&#xFF0C;&#x4E3A;&#x8FD9;&#x4E9B;&#x4F01;&#x4E1A;&#x5BFB;&#x627E;&#x548C;&#x57F9;&#x517B;&#x4EBA;&#x624D;&#x3002;</p>
<p>&#x201C;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x201D;&#xFF08;Nanodegreee, ND&#xFF09;&#x662F;Udacity&#x76EE;&#x524D;&#x7684;&#x4E3B;&#x6253;&#x4EA7;&#x54C1;&#xFF0C;&#x610F;&#x56FE;&#x8BA9;&#x5B66;&#x5458;&#x901A;&#x8FC7;9-12&#x4E2A;&#x6708;&#x7684;&#x4E1A;&#x4F59;&#x5B66;&#x4E60;&#xFF08;&#x6BCF;&#x6708;&#x81F3;&#x5C11;10&#x5C0F;&#x65F6;&#x6295;&#x5165;&#xFF09;&#x6210;&#x4E3A;&#x80FD;&#x591F;&#x80DC;&#x4EFB;&#x67D0;&#x4E2A;IT&#x6280;&#x672F;&#x5C97;&#x4F4D;&#x7684;&#x4EBA;&#x624D;&#xFF08;&#x521D;&#x7EA7;&#x4E3A;&#x4E3B;&#xFF09;&#x3002;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x7684;&#x6536;&#x8D39;&#x4EE5;&#x6708;&#x4E3A;&#x5355;&#x4F4D;&#xFF0C;&#x82F1;&#x6587;&#x7F51;&#x7AD9;&#x4E00;&#x822C;&#x662F;$199/&#x6708;&#xFF0C;&#x5728;&#x534E;&#x4EF7;&#x683C;&#x662F;&#xFFE5;980/&#x6708;&#xFF0C;&#x8FD9;&#x4E2A;&#x4EF7;&#x683C;&#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x652F;&#x4ED8;&#x4E00;&#x5BF9;&#x4E00;&#x8F85;&#x5BFC;&#xFF0C;&#x56E0;&#x4E3A;&#x8BFE;&#x7A0B;&#x5185;&#x5BB9;&#x662F;&#x514D;&#x8D39;&#x7684;&#x3002;</p>
<p>&#x4E0D;&#x8FC7;&#xFF0C;&#x4F60;&#x5E76;&#x4E0D;&#x9700;&#x8981;&#x4E00;&#x4E07;&#x591A;&#x5143;&#x624D;&#x80FD;&#x83B7;&#x5F97;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#xFF0C;&#x56E0;&#x4E3A;Udacity&#x7684;&#x8003;&#x6838;&#x662F;&#x901A;&#x8FC7;&#x8BC4;&#x4F30;&#x4F60;&#x63D0;&#x4EA4;&#x7684;&#x6307;&#x5B9A;&#x9879;&#x76EE;&#x6765;&#x5B8C;&#x6210;&#x3002;&#x4F60;&#x5B8C;&#x5168;&#x53EF;&#x4EE5;&#x5148;&#x81EA;&#x5B66;&#x6240;&#x6709;&#x5185;&#x5BB9;&#xFF0C;&#x505A;&#x597D;&#x9879;&#x76EE;&#xFF0C;&#x518D;&#x4ED8;&#x8D39;&#x5B66;&#x4E60;&#x3002;&#x5229;&#x7528;&#x201C;&#x4E00;&#x5E74;&#x5185;&#x5B8C;&#x6210;&#x8FD4;&#x8FD8;&#x4E00;&#x534A;&#x5B66;&#x8D39;&#x201D;&#x7684;&#x653F;&#x7B56;&#xFF0C;&#x6700;&#x4F4E;&#x53EA;&#x9700;&#x4E00;&#x4E2A;&#x6708;&#x7684;&#x4EF7;&#x683C;&#x5C31;&#x53EF;&#x4EE5;&#x83B7;&#x5F97;&#x201C;&#x5B66;&#x4F4D;&#x8BC1;&#x201D;&#xFF08;&#x8FD4;&#x8FD8;&#x653F;&#x7B56;&#x8981;&#x6C42;&#x81F3;&#x5C11;&#x8BA2;&#x9605;&#x4E24;&#x4E2A;&#x6708;&#xFF09;&#x3002;</p>
<p><strong>&#x552F;&#x4E00;&#x7684;&#x95EE;&#x9898;&#x662F;&#xFF1A;&#x4F60;&#x80FD;&#x575A;&#x6301;&#x5B66;&#x4E60;&#x5417;&#xFF1F;</strong></p>
<p>Udacity&#x73B0;&#x6709;&#x5341;&#x4F59;&#x4E2A;&#x201C;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x201D;&#xFF0C;&#x5305;&#x62EC;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;&#x3001;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5DE5;&#x7A0B;&#x5E08;&#x3001;&#x524D;&#x7AEF;&#x5DE5;&#x7A0B;&#x5E08;&#x3001;&#x540E;&#x7AEF;&#x5DE5;&#x7A0B;&#x5E08;&#x3001;iOS&#x5E94;&#x7528;&#x5F00;&#x53D1;&#x3001;&#x5B89;&#x5353;&#x5E94;&#x7528;&#x5F00;&#x53D1;&#x5DE5;&#x7A0B;&#x5E08;&#x7B49;&#x3002;&#x90E8;&#x5206;&#x8BFE;&#x7A0B;&#x5DF2;&#x7ECF;&#x88AB;&#x8BD1;&#x6210;&#x4E2D;&#x6587;&#x3002;</p>
<h1 id="&#x8BFE;&#x524D;&#x51C6;&#x5907;">&#x8BFE;&#x524D;&#x51C6;&#x5907;</h1><p>&#x6211;&#x7684;&#x6570;&#x636E;&#x5206;&#x6790;&#x57FA;&#x7840;&#x8FD8;&#x4E0D;&#x9519;&#xFF0C;&#x6240;&#x4EE5;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;&#x8FD9;&#x4E2A;&#x4E00;&#x534A;&#x8BFE;&#x7A0B;&#x770B;&#x8D77;&#x6765;&#x90FD;&#x773C;&#x719F;&#x7684;ND&#x5C31;&#x6210;&#x4E86;&#x6211;&#x7684;&#x4E0A;&#x624B;&#x730E;&#x7269;&#x2026;&#x2026;</p>
<p>Udacity&#x6539;&#x7248;&#x4E4B;&#x540E;&#xFF0C;&#x589E;&#x52A0;&#x4E86;&#x4E0D;&#x5C11;&#x8D34;&#x5FC3;&#x7684;&#x529F;&#x80FD;&#xFF0C;&#x6BD4;&#x5982;&#x628A;&#x67D0;&#x4E2A;Nanodegree&#x9700;&#x8981;&#x591A;&#x5C11;&#x65F6;&#x95F4;&#x5B8C;&#x6210;&#x90FD;&#x8BA1;&#x7B97;&#x597D;&#xFF0C;&#x751A;&#x81F3;&#x8FDE;&#x6BCF;&#x4E00;&#x8282;&#x8BFE;&#x7684;&#x65F6;&#x95F4;&#x90FD;&#x663E;&#x793A;&#x5728;&#x5B66;&#x4E60;&#x8BA1;&#x5212;&#x4E2D;&#xFF1B;&#x786E;&#x5B9E;&#x4E3A;&#x4E1A;&#x4F59;&#x5B66;&#x4E60;&#x63D0;&#x4F9B;&#x4E86;&#x4E0D;&#x5C11;&#x4FBF;&#x5229;&#x3002;</p>
<p>&#x7136;&#x540E;&#x6211;&#x5C31;&#x5728;&#x9996;&#x6708;&#x514D;&#x8D39;&#x7684;&#x86CA;&#x60D1;&#x4E0B;&#x8BA2;&#x9605;&#x4E86;&#x8FD9;&#x4E2A;&#x5B66;&#x4F4D;&#x5566;&#x3002;&#x63A5;&#x7740;&#x5C31;&#x4E0D;&#x77E5;&#x4E0D;&#x89C9;&#x5730;&#x770B;&#x5B8C;&#x4E86;&#x7B2C;&#x4E00;&#x8BFE;&#x3002;&#x55EF;&#xFF0C;&#x8FD9;&#x4E0D;&#x662F;&#x7EDF;&#x8BA1;&#x5B66;101&#x7684;&#x5185;&#x5BB9;&#x561B;&#xFF0C;&#x771F;&#x7684;&#x5B8C;&#x5168;&#x65E0;&#x538B;&#x529B;&#x597D;&#x5417;&#xFF1F;</p>
<p>&#x5728;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x7684;&#x6B22;&#x8FCE;&#x89C6;&#x9891;&#x4E2D;&#xFF0C;&#x4E00;&#x4F4D;&#x77E5;&#x5FC3;&#x5927;&#x59D0;&#x544A;&#x8BC9;&#x6211;&#x4EEC;&#xFF1A;&#x65F6;&#x95F4;&#x6295;&#x5165;&#x662F;&#x6210;&#x529F;&#x5B8C;&#x6210;&#x5B66;&#x4F4D;&#x7684;&#x6700;&#x91CD;&#x8981;&#x56E0;&#x7D20;&#xFF0C;&#x4E00;&#x5B9A;&#x8981;&#x5728;&#x81EA;&#x5DF1;&#x7684;&#x65E5;&#x7A0B;&#x4E2D;&#x9884;&#x7559;&#x51FA;&#x5B66;&#x4E60;&#x65F6;&#x95F4;&#x3002;Udacity&#x63A8;&#x8350;&#x6BCF;&#x5468;&#x81F3;&#x5C11;&#x82B1;10&#x5C0F;&#x65F6;&#x5B66;&#x4E60;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#xFF0C;&#x4E14;&#x6700;&#x597D;&#x4E0D;&#x8981;&#x4E00;&#x6B21;&#x6027;&#x5B66;&#x4E60;10&#x5C0F;&#x65F6;&#xFF0C;&#x5206;&#x6563;&#x5230;&#x6BCF;&#x5929;&#x8F83;&#x597D;&#x3002;</p>
<p>&#x6211;&#x7B97;&#x4E86;&#x7B97;&#xFF0C;&#x6BCF;&#x5929;&#x5B66;&#x4E60;3-4&#x5C0F;&#x65F6;&#x662F;&#x80FD;&#x4FDD;&#x8BC1;&#x7684;&#x3002;&#x8FD9;&#x6837;&#x4E00;&#x5468;20&#x5C0F;&#x65F6;&#x90FD;&#x6709;&#x4F59;&#x4E86;&#x3002;&#x4E8E;&#x662F;&#x624B;&#x4E00;&#x6296;&#xFF0C;&#x53C8;&#x8BA2;&#x9605;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7684;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x3002;&#x82B1;&#x5F00;&#x4E24;&#x6735;&#xFF0C;&#x5404;&#x8868;&#x4E00;&#x679D;&#xFF0C;&#x5173;&#x4E8E;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x7684;ND&#x53E6;&#x6587;&#x9610;&#x8FF0;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x5C31;&#x662F;&#x5B66;&#x4E60;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x7684;&#x8BB0;&#x5F55;&#x3002;</p>
<h1 id="Project_0">Project 0</h1><p>&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x9009;&#x505A;&#x9879;&#x76EE;&#xFF0C;&#x901A;&#x8FC7;&#x505A;&#x8FD9;&#x4E2A;&#x9879;&#x76EE;&#x53EF;&#x4EE5;&#x4E0A;&#x624B;&#x672A;&#x6765;&#x672C;&#x8BFE;&#x7A0B;&#x6240;&#x9700;&#x7684;&#x5DE5;&#x5177;&#x3002;</p>
<h2 id="Python&#x6570;&#x636E;&#x5206;&#x6790;&#x5F00;&#x53D1;&#x73AF;&#x5883;&#xFF1A;Anaconda">Python&#x6570;&#x636E;&#x5206;&#x6790;&#x5F00;&#x53D1;&#x73AF;&#x5883;&#xFF1A;Anaconda</h2><p>&#x505A;&#x8FD9;&#x4E2A;&#x9879;&#x76EE;&#x9996;&#x5148;&#x8981;&#x5B89;&#x88C5;<a href="https://www.continuum.io/downloads" target="_blank" rel="external"> Anaconda </a>&#xFF0C;&#x4EE5;&#x4FBF;&#x6109;&#x5FEB;&#x5730;&#x4F7F;&#x7528;Python&#x3002;&#x4E0B;&#x8F7D;&#x5B89;&#x88C5;&#x81EA;&#x4E0D;&#x7528;&#x63D0;&#x3002;&#x5B98;&#x65B9;&#x63D0;&#x4F9B;&#x7684;<a href="http://conda.pydata.org/docs/test-drive.html#managing-conda" target="_blank" rel="external"> Test Drive </a>&#x4F1A;&#x6559;&#x4E00;&#x4E9B;&#x57FA;&#x672C;&#x914D;&#x7F6E;&#x65B9;&#x6CD5;&#x3002;</p>
<h2 id="Python&#x4EA4;&#x4E92;&#x8BA1;&#x7B97;&#x5E73;&#x53F0;&#xFF1A;IPython_Notebook">Python&#x4EA4;&#x4E92;&#x8BA1;&#x7B97;&#x5E73;&#x53F0;&#xFF1A;IPython Notebook</h2><p>&#x672C;&#x9879;&#x76EE;&#x7528;&#x5230;&#x4E86;IPython Notebook&#x3002;</p>
<p>&#x8FD9;&#x91CC;<a href="http://mindonmind.github.io/2013/02/08/ipython-notebook-interactive-computing-new-era/" target="_blank" rel="external">&#x5F15;&#x7528;&#x4E00;&#x6BB5;</a>&#x5BF9;IPython Notebook&#x7684;&#x4ECB;&#x7ECD;&#xFF1A;</p>
<blockquote>
<p>IPython Notebook &#x65E2;&#x662F;&#x4E00;&#x4E2A;&#x4EA4;&#x4E92;&#x8BA1;&#x7B97;&#x5E73;&#x53F0;&#xFF0C;&#x53C8;&#x662F;&#x4E00;&#x4E2A;&#x8BB0;&#x5F55;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;&#x7684;&#x300C;&#x7B14;&#x8BB0;&#x672C;&#x300D;&#x3002;&#x5B83;&#x7531;&#x670D;&#x52A1;&#x7AEF;&#x548C;&#x5BA2;&#x6237;&#x7AEF;&#x4E24;&#x90E8;&#x5206;&#x7EC4;&#x6210;&#xFF0C;&#x5176;&#x4E2D;&#x670D;&#x52A1;&#x7AEF;&#x8D1F;&#x8D23;&#x4EE3;&#x7801;&#x7684;&#x89E3;&#x91CA;&#x4E0E;&#x8BA1;&#x7B97;&#xFF0C;&#x800C;&#x5BA2;&#x6237;&#x7AEF;&#x8D1F;&#x8D23;&#x4E0E;&#x7528;&#x6237;&#x8FDB;&#x884C;&#x4EA4;&#x4E92;&#x3002;&#x670D;&#x52A1;&#x7AEF;&#x53EF;&#x4EE5;&#x8FD0;&#x884C;&#x5728;&#x672C;&#x673A;&#x4E5F;&#x53EF;&#x4EE5;&#x8FD0;&#x884C;&#x5728;&#x8FDC;&#x7A0B;&#x670D;&#x52A1;&#x5668;&#xFF0C;&#x5305;&#x542B;&#x8D1F;&#x8D23;&#x8FD0;&#x7B97;&#x7684; IPython kernel (&#x4E0E; QT Console &#x7684; kernel &#x76F8;&#x540C;) &#x4EE5;&#x53CA;&#x4E00;&#x4E2A; HTTP/S &#x670D;&#x52A1;&#x5668; (Tornado)&#x3002;&#x800C;&#x5BA2;&#x6237;&#x7AEF;&#x5219;&#x662F;&#x4E00;&#x4E2A;&#x6307;&#x5411;&#x670D;&#x52A1;&#x7AEF;&#x5730;&#x5740;&#x7684;&#x6D4F;&#x89C8;&#x5668;&#x9875;&#x9762;&#xFF0C;&#x8D1F;&#x8D23;&#x63A5;&#x53D7;&#x7528;&#x6237;&#x7684;&#x8F93;&#x5165;&#x5E76;&#x8D1F;&#x8D23;&#x6E32;&#x67D3;&#x8F93;&#x51FA;&#x3002;</p>
</blockquote>
<p>&#x5982;&#x4ECA;IPython Notebook&#x5DF2;&#x7ECF;&#x66F4;&#x540D;&#x4E3A;jupyter&#xFF08;&#x8BF4;&#x5B9E;&#x8BDD;&#x611F;&#x89C9;&#x4E0D;&#x5982;&#x539F;&#x6765;&#x7684;&#x540D;&#x5B57;&#xFF09;&#x3002;</p>
<p>&#x6839;&#x636E;Udacity&#x7ED9;&#x51FA;&#x7684;&#x4E0B;&#x8F7D;&#x94FE;&#x63A5;&#x4E0B;&#x8F7D;ipynb&#x6587;&#x4EF6;&#x540E;&#xFF0C;&#x5728;&#x4FDD;&#x5B58;&#x6587;&#x4EF6;&#x7684;&#x8DEF;&#x5F84;&#x4E0B;&#x8F93;&#x5165;&#xFF1A;</p>
<p><code>jupyter notebook Data_Analyst_ND_Project0.ipynb</code></p>
<p>&#x5373;&#x53EF;&#x542F;&#x52A8;&#x672C;&#x5730;&#x670D;&#x52A1;&#x5668;&#xFF0C;&#x5728;&#x6D4F;&#x89C8;&#x5668;&#x4E2D;&#x67E5;&#x770B;&#x548C;&#x7F16;&#x8F91;&#x8BE5;&#x7B14;&#x8BB0;&#x672C;&#x3002;</p>
<h2 id="Project_0:_Chopsticks!">Project 0: Chopsticks!</h2><h3 id="&#x80CC;&#x666F;">&#x80CC;&#x666F;</h3><p>&#x7814;&#x7A76;&#x8005;&#x60F3;&#x8981;&#x627E;&#x51FA;&#x6210;&#x4EBA;&#x548C;&#x513F;&#x7AE5;&#x4F7F;&#x7528;&#x7B77;&#x5B50;&#x7684;&#x6700;&#x9002;&#x5B9C;&#x957F;&#x5EA6;&#x3002;&#x7B77;&#x5B50;&#x4F7F;&#x7528;&#x7684;&#x8868;&#x73B0;&#x7531;&#x5939;&#x8D77;&#x82B1;&#x751F;&#x653E;&#x5230;&#x676F;&#x5B50;&#x91CC;&#x7684;&#x82B1;&#x751F;&#x4E2A;&#x6570;&#x6765;&#x8BC4;&#x4F30;&#x3002;</p>
<p><a href="http://www.ncbi.nlm.nih.gov/pubmed/15676839" target="_blank" rel="external">&#x8FD9;&#x9879;&#x7814;&#x7A76;</a>&#x53D1;&#x8868;&#x5728;1991&#x5E74;&#x7684;Applied Ergonomics&#x4E0A;&#x3002;</p>
<h3 id="&#x5B9E;&#x9A8C;">&#x5B9E;&#x9A8C;</h3><p>&#x5B9E;&#x9A8C;&#x8FDB;&#x884C;&#x4E86;&#x4E24;&#x6B21;&#xFF0C;&#x5206;&#x522B;&#x5BF9;31&#x540D;&#x7537;&#x6027;&#x521D;&#x7EA7;&#x5B66;&#x9662;&#xFF08;&#x76F8;&#x5F53;&#x4E8E;&#x5927;&#x5B66;&#x9884;&#x79D1;&#xFF09;&#x5B66;&#x751F;&#x548C;21&#x540D;&#x5C0F;&#x5B66;&#x751F;&#x8FDB;&#x884C;&#x3002;&#x4F7F;&#x7528;&#x4E86;&#x957F;&#x5EA6;&#x5206;&#x522B;&#x4E3A;180, 210, 240, 270, 300 &#x548C;330 mm&#x7684;&#x7B77;&#x5B50;&#x3002;&#x5B9E;&#x9A8C;&#x91C7;&#x7528;randomised complete block design. </p>
<h3 id="&#x6570;&#x636E;">&#x6570;&#x636E;</h3><p>&#x672C;&#x9879;&#x76EE;&#x53EA;&#x91C7;&#x7528;&#x6210;&#x4EBA;&#x7EC4;&#x7684;&#x6570;&#x636E;&#x3002;&#x6570;&#x636E;&#x5206;&#x4E3A;&#x4E09;&#x5217;&#xFF1A;&#x5939;&#x53D6;&#x6548;&#x7387;&#x3001;&#x5B9E;&#x9A8C;&#x5BF9;&#x8C61;&#x7F16;&#x53F7;&#x3001;&#x7B77;&#x5B50;&#x957F;&#x5EA6;&#x3002;</p>
<p>&#x6BCF;&#x4F4D;&#x6210;&#x4EBA;&#x90FD;&#x4F7F;&#x7528;&#x4E86;&#x4E00;&#x904D;&#x6240;&#x6709;&#x4E0D;&#x540C;&#x957F;&#x5EA6;&#x7684;&#x7B77;&#x5B50;&#x3002;</p>
<h3 id="&#x95EE;&#x9898;">&#x95EE;&#x9898;</h3><ol>
<li>Independent Variable in the Experiment?</li>
<li>Dependent Variable in the Experiment?</li>
<li>Operational Definition of the Dependent Variable?</li>
<li>Controlled Variables? (list at least two)</li>
<li>Best chopstick length?</li>
<li>Relationship between length and efficiency?</li>
<li>Do you agree with the claim made by the researchers and why?</li>
</ol>
<p>&#xFF08;&#x5F85;&#x7EED;&#xFF09;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>&#x4ECB;&#x7ECD;Udacity&#xFF08;&#x5728;&#x534E;&#x540D;&#x79F0;&#x201C;&#x4F18;&#x8FBE;&#x5B66;&#x57CE;&#x201D;&#xFF09;&#x7684;&#x201C;&#x7EB3;&#x7C73;&#x5B66;&#x4F4D;&#x201D;&#x9879;&#x76EE;&#xFF0C;&#x53CA;&#x5176;&#x6570;&#x636E;&#x5206;&#x6790;&#x5E08;&#x9879;&#x76EE;&#x7684;&#x57FA;&#x672C;&#x60C5;&#x51B5;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Data Analyst" scheme="http://tech.liuxiaozhen.com/tags/Data-Analyst/"/>
    
      <category term="Nanodegree" scheme="http://tech.liuxiaozhen.com/tags/Nanodegree/"/>
    
      <category term="Statistics" scheme="http://tech.liuxiaozhen.com/tags/Statistics/"/>
    
      <category term="Udacity" scheme="http://tech.liuxiaozhen.com/tags/Udacity/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[How to Use Git and GitHub]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/04/06/udacity-GitHub-Notes/"/>
    <id>http://tech.liuxiaozhen.com/2016/04/06/udacity-GitHub-Notes/</id>
    <published>2016-04-05T17:13:45.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>Udacity&#x8BFE;&#x7A0B;&#x4E4B;&#x4E00;&#xFF0C;&#x53EF;&#x80FD;&#x662F;&#x6700;&#x5570;&#x55E6;&#x7684;GitHub&#x6559;&#x7A0B;&#xFF1A;&#xFF09;</p>
<a id="more"></a>
<p><strong>This note is for the Udacity course &#x201C;How to Use Git and Github&#x201D;.</strong></p>
<h2 id="Lesson_1">Lesson 1</h2><h3 id="Find_differences_between_two_large_files">Find differences between two large files</h3><p><strong>Commands</strong>:</p>
<ul>
<li>Windows: FC</li>
<li>Mac/Linux: Diff</li>
</ul>
<blockquote>
<p>Reflect: How did viewing a diff between two versions help you spot the bug?<br>Answer: By looking at the differences between two versions, I know which changes have been made that caused the bug.</p>
</blockquote>
<p>Choose a text editor: Notepad++, Sublim, Atom, emacs, vim, etc. </p>
<p><strong>I picked Atom.</strong></p>
<h3 id="Versions">Versions</h3><ul>
<li>Saving manual copies</li>
<li>Dropbox (periodically save versions automatically)</li>
<li>Google Docs (periodically save versions automatically)</li>
<li>Wikipedia (versions by different authors)</li>
<li>Git</li>
<li>SVN</li>
</ul>
<blockquote>
<p>Reflect: How could having easy access to the entire history of a file make you a more efficient programmer in the long term?<br>I don&#x2019;t have to remember all the changes and the reasons for making them. With all the histories stored in exact forms, I can just look back at them when needed. Also, it helps me to learn from my own mistakes and allow me to do experiments without worrying about breaking things. </p>
</blockquote>
<p><strong>Feature Comparison Chart</strong></p>
<blockquote>
<p>Quiz: When to save: as a programer, when would you want to have version of your code saved?</p>
<ul>
<li>At regular intervals (e.g. every hour)</li>
<li>Whenever a large enough change is made (e.g. 50 lines)</li>
<li>Whenever there is a long pause in editing</li>
<li><strong>When you choose to save a version</strong></li>
</ul>
</blockquote>
<h3 id="Mannual_Commits">Mannual Commits</h3><p>Git requires a message with each commit</p>
<p>Cases that need a new commit:</p>
<ul>
<li>fix off-by-one bug</li>
<li>add cool new feature</li>
<li>improve user docs</li>
</ul>
<h3 id="Use_Git_to_View_History">Use Git to View History</h3><p><strong>[Offline]</strong></p>
<ul>
<li>Each commit has an ID, an Autor, Date/Time, and a message</li>
<li><code>git diff ID1 ID2</code></li>
<li><p>Judgment Call</p>
<blockquote>
<p>Choosing when to commit is a judgment call, and it&#x2019;s not always cut-and-dried. When choosing whether to commit, just keep in mind that each commit should have one clear, logical purpose, and you should never do too much work without committing.</p>
</blockquote>
</li>
</ul>
<h3 id="Commits_with_Multiple_Files">Commits with Multiple Files</h3><ul>
<li>A repository contains multiple files</li>
<li>Make changes in different files together and track in one commit<blockquote>
<p>Reflect: Why do you think some version control systems, like Git, allow saving multiple files in one commit, while others, like Google Docs, treat each file separately?<br>Because Git takes a mannual and logical approach, and keeps the records in one git file for each repo. For others, they keep the records as part of the information related to one file.</p>
</blockquote>
</li>
</ul>
<h3 id="Git_Commands">Git Commands</h3><p><strong>[Online]</strong></p>
<ul>
<li>Clone a repo <code>git clone _repo_url_</code><br>(<a href="https://github.com/udacity/asteroids.git" target="_blank" rel="external">https://github.com/udacity/asteroids.git</a>)</li>
<li><code>git log</code></li>
<li><code>git diff</code></li>
<li>Check commit: <code>git checkout _commit ID_</code></li>
</ul>
<h3 id="Making_Git_configurations">Making Git configurations</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global core<span class="class">.editor</span> <span class="string">&quot;atom --wait&quot;</span></span><br><span class="line">git config --global push<span class="class">.default</span> upstream</span><br><span class="line">git config --global merge<span class="class">.conflictstyle</span> diff3</span><br></pre></td></tr></table></figure>
<h3 id="Summary">Summary</h3><ul>
<li>Why use Git</li>
<li>Git Setup</li>
<li>Git commands: clone, log, diff, checkout</li>
</ul>
<h2 id="Lesson_2">Lesson 2</h2><h3 id="Initialize">Initialize</h3><p><strong>[Offline]</strong></p>
<ul>
<li><code>git init</code></li>
<li>When a git is initialized, no commit is included</li>
<li>Check git status: <code>git status</code></li>
</ul>
<h3 id="Choosing_what_changes_to_commit">Choosing what changes to commit</h3><ul>
<li>working directory -&gt; staging area -&gt; repository</li>
<li><code>git add _file_to_update_</code> will add named files to staging area</li>
<li>remove from staging area by using <code>git reset</code></li>
</ul>
<h3 id="Write_a_commit_message">Write a commit message</h3><ul>
<li><code>git commit</code> will open the editor</li>
<li>standard practice: write a message as if it is a command</li>
<li><code>git commit -m &quot;Commit message&quot;</code></li>
<li>commit message <a href="http://udacity.github.io/git-styleguide/" target="_blank" rel="external">style guide</a></li>
</ul>
<h3 id="Git_diff_revisited">Git diff revisited</h3><ul>
<li><code>git diff</code> will compare the <strong>working directory</strong> with the <strong>staging area</strong></li>
<li><code>git diff --staged</code> will compare the <strong>staging area</strong> with the <strong>repository</strong></li>
<li>_Be careful! <code>git reset --hard</code> is not reversable_</li>
<li>Leave &#x2018;detached HEAD&#x2019; state: <code>git checkout master</code></li>
</ul>
<h3 id="Create_and_commit_branches">Create and commit branches</h3><ul>
<li>One branch is enough: fix bug, new feature, update docs</li>
<li>More than one branch: experimental feature, Italian version</li>
<li>Most recent commit of a branch: tip of a branch</li>
<li>Show all the branches and the current branch is marked with * : <code>git branch</code></li>
<li>Create a branch: <code>git branch &quot;branch_name&quot;</code></li>
<li>Switch to a branch: <code>git checkout &quot;branch_name&quot;</code></li>
</ul>
<h3 id="Branches_for_Collaboration">Branches for Collaboration</h3><p><strong>[Online]</strong></p>
<ul>
<li>remote branch</li>
<li>branch has parents &#x201C;reachability&#x201D;</li>
<li>checkout a commit as a new branch: <code>git checkout -b _new_branch_name_</code></li>
</ul>
<h3 id="Combining_Simple_Files">Combining Simple Files</h3><ul>
<li>merged branch has both parents</li>
<li><code>git merge branch_1 branch_2</code></li>
<li><code>git show</code> show the diff of a commit with its parent</li>
<li>deleting branches: <code>git branch -d _branch_name_</code></li>
<li>Merge conflict: when both branches modify the same part of the files</li>
<li>Commit the conflict resolution</li>
<li><code>git log -n 1</code> show only 1 commit log</li>
</ul>
<h3 id="Summary-1">Summary</h3><ul>
<li>Initialize git</li>
<li>Create commits</li>
<li>Create and commit branches</li>
<li>Merge branches</li>
</ul>
<h2 id="Lesson_3">Lesson 3</h2><h3 id="Sync_with_repositories_on_GitHub">Sync with repositories on GitHub</h3><ul>
<li>Remote repo</li>
<li>push and pull</li>
<li>no working directory or staging area on GitHub side</li>
</ul>
<h3 id="Forking_a_Repository">Forking a Repository</h3><ul>
<li>click fork button</li>
<li>= create a clone on GitHub instead of on your local computer.</li>
<li>Can add collaborators</li>
<li><code>git remote -v</code></li>
<li>push</li>
</ul>
<h3 id="Merge_the_Changes_Together">Merge the Changes Together</h3><ul>
<li>Fast-forward merge</li>
<li><code>git merge master origin/master</code></li>
<li>resolve conflict</li>
</ul>
<h3 id="Pull_request">Pull request</h3><ul>
<li>Ask for your pull request to be merged</li>
<li>after merging, delete branch</li>
</ul>
<h3 id="Summary-2">Summary</h3><ul>
<li>Clone and Fork</li>
<li>Merge and Pull request</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>Udacity&#x8BFE;&#x7A0B;&#x4E4B;&#x4E00;&#xFF0C;&#x53EF;&#x80FD;&#x662F;&#x6700;&#x5570;&#x55E6;&#x7684;GitHub&#x6559;&#x7A0B;&#xFF1A;&#xFF09;</p>]]>
    
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[Machine Learning by Stanford University Week 2]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/04/05/Machine-learning-W2/"/>
    <id>http://tech.liuxiaozhen.com/2016/04/05/Machine-learning-W2/</id>
    <published>2016-04-05T07:00:00.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>Andrew Ng&#x5728;Coursera&#x4E0A;&#x5F00;&#x8BBE;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x8BFE;&#x7A0B;&#x7B2C;&#x4E8C;&#x5468;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x4ECB;&#x7ECD;&#x4E86;&#x591A;&#x5143;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 March session.</strong></p>
<h2 id="Environment_Setup">Environment Setup</h2><p>Octave and MATLAB are preferred in machine learning. </p>
<p>For more information about Octave and MATLAB, see:<br><a href="https://www.coursera.org/learn/machine-learning/supplement/Mlf3e/more-octave-matlab-resources" target="_blank" rel="external">https://www.coursera.org/learn/machine-learning/supplement/Mlf3e/more-octave-matlab-resources</a></p>
<h2 id="Multivariate_Linear_Regression">Multivariate Linear Regression</h2><h3 id="Multiple_Features">Multiple Features</h3><p>&#x4E3A;&#x4EC0;&#x4E48;&#x9700;&#x8981;multiple features? &#x5BF9;&#x4E8E;&#x8BB8;&#x591A;&#x95EE;&#x9898;&#xFF0C;&#x5F71;&#x54CD;&#x9884;&#x6D4B;&#x7ED3;&#x679C;&#x7684;&#x5E76;&#x4E0D;&#x6B62;&#x4E00;&#x4E2A;&#x56E0;&#x7D20;&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x9700;&#x8981;&#x591A;&#x4E2A;&#x53D8;&#x91CF;&#x6765;&#x53CD;&#x6620;&#x4E0D;&#x540C;&#x7684;&#x5F71;&#x54CD;&#x56E0;&#x7D20;&#x3002;</p>
<p>Multiple Features&#x5982;&#x4F55;&#x7528;&#x7EBF;&#x6027;&#x65B9;&#x7A0B;&#x5F0F;&#x6765;&#x8868;&#x793A;&#xFF1F;</p>
<p>$h_\theta(x) = \theta_0 +\theta_1x_1+\theta_2x_2+&#x2026;+\theta_nx_n = \theta^TX$</p>
<h3 id="Cost_Function_for_Multiple_Variables">Cost Function for Multiple Variables</h3><p>$\theta$ is an $n+1$ -dimention vector</p>
<p>$$ J(\theta_0,\theta_1,&#x2026;,\theta_n)=\frac1{2m}\sum_{i=1}^m(h_\theta(x^{(i)}-y^{(i)})^2 $$</p>
<h3 id="Gradient_Descent_for_Multiple_Variables">Gradient Descent for Multiple Variables</h3><p>Repeat{</p>
<p>$$\theta_j := \theta_j - \alpha\frac1m\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}$$</p>
<p>(simutaneously update $\theta_j$ for $j = 0,&#x2026;,n$</p>
<p>notice that $x_0 = 1$)</p>
<p>}</p>
<h3 id="Feature_Scaling">Feature Scaling</h3><ul>
<li><p>Idea: get every feature into approximately a $-1\leq {x_i}\leq 1$ range</p>
</li>
<li><p>Mean normalization: replace $x_i$ with $x_i - \mu_i$ to make features have approximately zero mean (Do not apply to $x_0 = 1$)</p>
</li>
</ul>
<h3 id="Learning_Rate_$\alpha$">Learning Rate $\alpha$</h3><ul>
<li>If $\alpha$ is too small: slow convergence.</li>
<li>If $\alpha$ is too large: $J(\theta)$ may not decrease on every iteration; may not converge. (slow converge also possible)</li>
<li>To choose $\alpha$, try: &#x2026;,0.001, 0.01, 0.1, 1,&#x2026;</li>
</ul>
<h3 id="Features_and_Polynomial_Regression">Features and Polynomial Regression</h3><ul>
<li><p>Polynomial regression example:    $\theta_0+\theta_1x+\theta_2x^2+\theta_3x^3$; let $x_1 = x, x_2 = x^2, x_3 = x^3$</p>
</li>
<li><p>Other possiblities: $\theta_0+\theta_1x+\theta_2\sqrt{x}$, let $x_1 = x, x_2 = \sqrt{x}$</p>
</li>
</ul>
<h2 id="Computing_Parameters_Analytically">Computing Parameters Analytically</h2><p>Suppose there are $m$ examples; $n$ features</p>
<p>$\theta = (X^TX)^{-1}X^Ty$<br>$(X^TX)^{-1}$ is inverse of matrix $X^TX$</p>
<p>if $m &lt; n$,<br>$X^TX$ may be non-inversible. </p>
<p>Therefore use <code>pinv</code> in Octave:<br><code>pinv(X&apos;*X)*X&apos;*y</code></p>
<table>
<thead>
<tr>
<th>Gradient Discent</th>
<th>Normal Equation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Need to choose $\alpha$</td>
<td>No need to choose $\alpha$</td>
</tr>
<tr>
<td>Needs many iterations</td>
<td>Don&#x2019;t need to iterate</td>
</tr>
<tr>
<td>Works well even when $n$ is large</td>
<td>Need to compute $(X^TX)^{-1}$ ($O(n^3)$), slow if $n$ is very large</td>
</tr>
</tbody>
</table>
<p>Therefore, if n is less than 1000, use normal equation. Otherwise, use gradient descent.</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Andrew Ng&#x5728;Coursera&#x4E0A;&#x5F00;&#x8BBE;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x8BFE;&#x7A0B;&#x7B2C;&#x4E8C;&#x5468;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x4ECB;&#x7ECD;&#x4E86;&#x591A;&#x5143;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Linear Regression" scheme="http://tech.liuxiaozhen.com/tags/Linear-Regression/"/>
    
      <category term="Machine Learning" scheme="http://tech.liuxiaozhen.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Machine Learning by Stanford University Week 1]]></title>
    <link href="http://tech.liuxiaozhen.com/2016/03/10/Machine-learning-W1/"/>
    <id>http://tech.liuxiaozhen.com/2016/03/10/Machine-learning-W1/</id>
    <published>2016-03-10T12:41:19.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>Andrew Ng&#x5728;Coursera&#x4E0A;&#x5F00;&#x8BBE;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x8BFE;&#x7A0B;&#x7B2C;&#x4E00;&#x5468;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x4ECB;&#x7ECD;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x57FA;&#x672C;&#x5B9A;&#x4E49;&#xFF0C;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x53CA;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#xFF0C;&#x4EE5;&#x53CA;&#x5355;&#x53D8;&#x91CF;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 March session.</strong></p>
<h2 id="Introduction">Introduction</h2><p>Definition of Machine Learning (Tom Mitchell): </p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.</p>
</blockquote>
<h3 id="Supervised_Learning">Supervised Learning</h3><ul>
<li>Correct outputs are known. </li>
<li>Categorized into <strong>regression</strong> and <strong>classification</strong> problems</li>
<li>Regression problem: predict results within a continuous output</li>
<li>Classification problem: predict results in a discrete output (0 or 1)</li>
</ul>
<p>Example: </p>
<ul>
<li>Boston Housing price vs size (regression)</li>
<li>Breast cancer malignant vs benign (classification)<ul>
<li>more than one attribute</li>
</ul>
</li>
</ul>
<h3 id="Unsupervised_Learning">Unsupervised Learning</h3><ul>
<li>No known correct output (feedback)</li>
<li>Derive data structure by clustering the data based on relationships among the variables in the data</li>
<li>Examples: google story collection; cocktail party (distiguish two voices)</li>
</ul>
<h2 id="Linear_Regression_with_One_Variable">Linear Regression with One Variable</h2><h3 id="Model_Representation">Model Representation</h3><p>Training set of housing prices (Portland, OR)<br>Notation:<br>$m$ = Number of training examples<br>$x$&#x2019;s = &#x201C;input&#x201D; variable / features<br>$y$&#x2019;s = &#x201C;output&#x201D; variable / &#x201C;target&#x201D; variable</p>
<p>$(x,y)$ - one training example</p>
<p>$(x^{(i)},y^{(i)})$ - $i^{th}$ training example</p>
<p><img src="/2016/03/10/Machine-learning-W1/Coursera-ml-w1-01.png" alt=""></p>
<p>How do we represent $h$?</p>
<p>  $$h_{\theta}(x) = \theta_0+\theta_1x$$</p>
<h3 id="Cost_Function">Cost Function</h3><p><strong>Idea</strong>: </p>
<p>Choose ${\theta_0}$, ${\theta_1}$ so that $h_{\theta}(x)$ is close to $y$ for our training examples $(x,y)$</p>
<h3 id="Cost_Function_-_Intuition">Cost Function - Intuition</h3><p>Hypothesis: $$h_{\theta}(x) = \theta_0+\theta_1x$$</p>
<p>Parameters: $\theta_0, \theta_1$</p>
<p>Cost Function:</p>
<p>$$J (\theta_0,\theta_1) = \frac 1{2m}{\sum_{i=1}^m\left(h_{\theta}(x^{(i)})-y^{(i)}\right)^2} $$</p>
<p>Goal:<br> $\text{minimize}\quad J(\theta_0,\theta_1)$</p>
<p><img src="/2016/03/10/Machine-learning-W1/Coursera-ml-w1-02.png" alt=""></p>
<h3 id="Gradient_Descent">Gradient Descent</h3><p>Have some function $J(\theta_0,\theta_1)$</p>
<p>want $\min \ J(\theta_0,\theta_1)$</p>
<p>Outline:</p>
<ul>
<li>start with some $\theta_0,\theta_1$</li>
<li>keep changing $\theta_0,\theta_1$ to reduce $J(\theta_0,\theta_1)$ until we hopefully end up at a minimum</li>
</ul>
<h3 id="Gradient_descent_algorithm">Gradient descent algorithm</h3><p>repeat until convergence {</p>
<p>$$\theta_j := \theta_j - \alpha \frac{\partial} {\partial \theta_j} J(\theta_0,\theta_1) $$     ( for $j = 0$ and $j =1$)</p>
<p>}</p>
<p><strong>Correct: simultaneous update $\theta_0$ and $\theta_1$</strong></p>
<p>$\alpha$ is the learning rate. </p>
<ul>
<li><p>if $\alpha$ is too small, gradient descent can be slow. </p>
</li>
<li><p>if $\alpha$ is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge. </p>
</li>
</ul>
<p>Gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed. </p>
<h3 id="Gradient_Descent_for_Linear_Regression">Gradient Descent for Linear Regression</h3><p>repeat until convergence {</p>
<p>$$\theta_0 := \theta_0 - \alpha \frac1m \sum_{i=1}^m \left( h_\theta (x^{(i)})-y^{(i)}\right) $$</p>
<p>$$\theta_1 := \theta_1 - \alpha \frac1m \sum_{i=1}^m \left( h_\theta (x^{(i)})-y^{(i)} \right)\cdot x^{(i)} $$<br>}</p>
<h4 id="&#x201C;Batch&#x201D;_Gradient_Descent">&#x201C;Batch&#x201D; Gradient Descent</h4><p>Each step of gradient descent uses all the training examples</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>Andrew Ng&#x5728;Coursera&#x4E0A;&#x5F00;&#x8BBE;&#x7684;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x8BFE;&#x7A0B;&#x7B2C;&#x4E00;&#x5468;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x4ECB;&#x7ECD;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x57FA;&#x672C;&#x5B9A;&#x4E49;&#xFF0C;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#x53CA;&#x65E0;&#x76D1;&#x7763;&#x5B66;&#x4E60;&#xFF0C;&#x4EE5;&#x53CA;&#x5355;&#x53D8;&#x91CF;&#x7EBF;&#x6027;&#x56DE;&#x5F52;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Linear Regression" scheme="http://tech.liuxiaozhen.com/tags/Linear-Regression/"/>
    
      <category term="Machine Learning" scheme="http://tech.liuxiaozhen.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Python for Everybody by University of Michigan (1)]]></title>
    <link href="http://tech.liuxiaozhen.com/2015/12/06/Python-for-Everybody-1/"/>
    <id>http://tech.liuxiaozhen.com/2015/12/06/Python-for-Everybody-1/</id>
    <published>2015-12-06T03:51:47.000Z</published>
    <updated>2016-08-21T10:39:23.000Z</updated>
    <content type="html"><![CDATA[<p>&#x4ECB;&#x7ECD;&#x4E86;&#x7F16;&#x7A0B;&#x57FA;&#x672C;&#x77E5;&#x8BC6;&#xFF0C;Python&#x5B89;&#x88C5;&#xFF0C;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x53D8;&#x91CF;&#x7B49;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the first course of University of Michigan online series &#x201C;Python for Everybody Specialization&#x201D; taught by Professor Charles Severance on Coursera.org, 2015 October session.</strong></p>
<h1 id="Week_1">Week 1</h1><h2 id="Why_Program?">Why Program?</h2><h2 id="Hardware">Hardware</h2><ul>
<li>CPU</li>
<li>I/O</li>
<li>Main sMemory (RAM)</li>
<li>Secondary Memory</li>
</ul>
<h2 id="Python">Python</h2><ul>
<li>Vocabulary/Words - Variables and Reserved words</li>
<li>Sentence structure - valid syntax patterns</li>
<li>Story structure - constructing a program for a purpose</li>
</ul>
<h1 id="Week_2">Week 2</h1><h2 id="Install_Python">Install Python</h2><ul>
<li>IDLE</li>
<li>Python Downloads: <a href="https://www.python.org/downloads/" target="_blank" rel="external">https://www.python.org/downloads/</a></li>
<li>Text Editor</li>
</ul>
<h1 id="Week_3">Week 3</h1><h2 id="Simple_program">Simple program</h2><ul>
<li>Sequential steps</li>
<li>Conditional steps</li>
<li>Repeated steps</li>
</ul>
<h2 id="Think_like_a_program">Think like a program</h2><ul>
<li>How to find the largest number?</li>
</ul>
<h1 id="Week_4">Week 4</h1><h2 id="Expressions">Expressions</h2><ul>
<li>Variables and Constants <ul>
<li>Constants</li>
<li>Python variable name rules: start with letters, case sensitive</li>
</ul>
</li>
<li>Sentences or lines<ul>
<li>Assignment statement: <code>x = 2</code></li>
<li>Assignment with expression: <code>x = x + 2</code> <ul>
<li>Print statement: <code>print x</code></li>
</ul>
</li>
</ul>
</li>
<li>Operator<ul>
<li>Numeric expressions: +, -, _, /, *_, %</li>
<li>Operator precedence rules: parenthesis, power, multiplication, addition, left to right<ul>
<li>Reserved words</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Variables">Variables</h2><ul>
<li>Type<ul>
<li>Interger</li>
<li>Float</li>
<li>String</li>
<li>&#x2026;</li>
</ul>
</li>
<li>Type conversions<ul>
<li>Type of x: <code>type(x)</code></li>
<li>Convert x to an interger <code>int(x)</code></li>
<li>Convert x to a float<code>float(x)</code></li>
</ul>
</li>
<li>User Input<ul>
<li><code>nam = raw_input(&quot;Who are you?&quot;)</code></li>
</ul>
</li>
<li>Comments in Python: anything after <code>#</code></li>
<li>Variable naming style</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>&#x4ECB;&#x7ECD;&#x4E86;&#x7F16;&#x7A0B;&#x57FA;&#x672C;&#x77E5;&#x8BC6;&#xFF0C;Python&#x5B89;&#x88C5;&#xFF0C;&#x8868;&#x8FBE;&#x5F0F;&#xFF0C;&#x53D8;&#x91CF;&#x7B49;&#x3002;</p>]]>
    
    </summary>
    
      <category term="Coursera" scheme="http://tech.liuxiaozhen.com/tags/Coursera/"/>
    
      <category term="Python" scheme="http://tech.liuxiaozhen.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[启]]></title>
    <link href="http://tech.liuxiaozhen.com/2015/04/03/start/"/>
    <id>http://tech.liuxiaozhen.com/2015/04/03/start/</id>
    <published>2015-04-03T09:17:05.000Z</published>
    <updated>2016-08-21T11:55:35.000Z</updated>
    <content type="html"><![CDATA[<p><img src="/2015/04/03/start/dune.jpeg" alt=""></p>
<p>&#x4ECE;&#x5C0F;&#x5B66;&#x5C31;&#x5F00;&#x59CB;&#x7F16;&#x7A0B;&#xFF0C;&#x4F46;&#x662F;&#x4EC5;&#x9650;&#x4E8E;&#x597D;&#x73A9;&#xFF1B;&#x5728;&#x5B66;&#x4E60;&#x79D1;&#x7814;&#x4E2D;&#x5076;&#x5C14;&#x6D89;&#x53CA;&#x7F16;&#x7A0B;&#xFF0C;&#x4E5F;&#x4E0D;&#x8FC7;&#x662F;&#x7B80;&#x77ED;&#x7684;&#x51E0;&#x5341;&#x884C;&#x3002;&#x4ECE;2009&#x5E74;&#x5165;&#x624B;iPod Touch&#x81F3;&#x4ECA;&#xFF0C;&#x5173;&#x4E8E;App&#x7684;&#x60F3;&#x6CD5;&#x65E0;&#x6570;&#xFF0C;&#x5374;&#x59CB;&#x7EC8;&#x6CA1;&#x6709;&#x6210;&#x4E3A;&#x4E00;&#x4E2A;&#x771F;&#x6B63;&#x7684;&#x521B;&#x9020;&#x8005;&#x3002;</p>
<p>tinyfool&#x5728;&#x53BB;&#x5E74;&#x7684;&#x4E00;&#x7BC7;<a href="http://www.jianshu.com/p/c27906bb8061" target="_blank" rel="external">&#x300A;&#x5BFB;&#x627E;&#x548C;&#x7A81;&#x7834;&#x5FC3;&#x969C;&#x300B;</a>&#x4E2D;&#x8BF4;&#xFF1A;</p>
<blockquote>
<p>&#x4EBA;&#x751F;&#x4E2D;&#x603B;&#x6709;&#x4E9B;&#x969C;&#x788D;&#x963B;&#x6321;&#x7740;&#x4F60;&#x53BB;&#x505A;&#x4F60;&#x60F3;&#x505A;&#x7684;&#x4E8B;&#x60C5;&#xFF0C;&#x4F46;&#x662F;&#x8FD9;&#x4E9B;&#x969C;&#x788D;&#x91CC;&#x9762;&#x6709;&#x4E00;&#x4E9B;&#x662F;&#x7269;&#x7406;&#x969C;&#x788D;&#xFF0C;&#x5982;&#x679C;&#x4F60;&#x771F;&#x7684;&#x6CA1;&#x6709;&#x65F6;&#x95F4;&#x548C;&#x91D1;&#x94B1;&#xFF0C;&#x4E0D;&#x53BB;&#x65C5;&#x6E38;&#x4E5F;&#x5C31;&#x4E0D;&#x53BB;&#x65C5;&#x6E38;&#x4E86;&#x3002;&#x5982;&#x679C;&#x4F60;&#x6709;&#x65F6;&#x95F4;&#x3001;&#x6709;&#x91D1;&#x94B1;&#xFF0C;&#x4E5F;&#x6709;&#x4E00;&#x4E2A;&#x8BF4;&#x8D70;&#x5C31;&#x8D70;&#x7684;&#x5FC3;&#xFF0C;&#x4F46;&#x662F;&#x4F60;&#x54EA;&#x91CC;&#x90FD;&#x6CA1;&#x6709;&#x53BB;&#x8FC7;&#xFF0C;&#x90A3;&#x5C31;&#x662F;&#x5FC3;&#x969C;&#x3002;</p>
</blockquote>
<p>&#x5173;&#x4E8E;&#x7F16;&#x7A0B;&#xFF0C;&#x6211;&#x60F3;&#x6211;&#x5E76;&#x975E;&#x771F;&#x7684;&#x5B8C;&#x5168;&#x6CA1;&#x6709;&#x65F6;&#x95F4;&#xFF0C;&#x800C;&#x4EC5;&#x4EC5;&#x51FA;&#x4E8E;&#x5FC3;&#x969C;&#x800C;&#x6CA1;&#x6709;&#x505A;&#x3002;&#x8FD1;&#x5E74;&#x6765;&#xFF0C;&#x5728;&#x6548;&#x7387;&#x548C;&#x5FC3;&#x667A;&#x65B9;&#x9762;&#x6536;&#x83B7;&#x8BB8;&#x591A;&#xFF0C;&#x5BF9;&#x4E8E;&#x5F00;&#x542F;&#x8FD9;&#x6837;&#x4E00;&#x6BB5;&#x65C5;&#x7A0B;&#x6162;&#x6162;&#x6709;&#x4E86;&#x4FE1;&#x5FC3;&#x3002;&#x5199;&#x7B14;&#x8BB0;&#xFF0C;&#x66F4;&#x591A;&#x7684;&#x662F;&#x5E0C;&#x671B;&#x9760;&#x8F93;&#x51FA;&#x7684;&#x8FC7;&#x7A0B;&#x6765;&#x52A0;&#x5F3A;&#x5B66;&#x4E60;&#x6548;&#x679C;&#x3002;&#x82E5;&#x80FD;&#x5728;&#x6BD4;&#x7279;&#x4E16;&#x754C;&#xFF0C;&#x65E0;&#x610F;&#x95F4;&#x7ED9;&#x4E00;&#x4E9B;&#x4EBA;&#x5E2E;&#x52A9;&#xFF0C;&#x5219;&#x5E78;&#x751A;&#x81F3;&#x54C9;&#x3002;</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="/2015/04/03/start/dune.jpeg" alt=""></p>
<p>&#x4ECE;&#x5C0F;&#x5B66;&#x5C31;&#x5F00;&#x59CB;&#x7F16;&#x7A0B;&#xFF0C;&#x4F46;&#x]]>
    </summary>
    
  </entry>
  
</feed>