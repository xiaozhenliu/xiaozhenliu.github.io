
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Machine Learning By Stanford University Week 3 | Live in the Future, then Build What&#39;s Missing</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="Liu Xiaozhen">
    

    
    <meta name="description" content="3. Logistic Regression and Regularization&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x903B;&amp;#x8F91;&amp;#x56DE;&amp;#x5F52;&amp;#x5206;&amp;#x6790;&amp;#xFF08;&amp;#x5206;&amp;#x7C7B;&amp;#x95EE;&amp;#x9898;&amp;#x6C42;&amp;#x89E3">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning By Stanford University Week 3">
<meta property="og:url" content="http://tech.liuxiaozhen.com/2016/05/14/Machine-Learning-W3/index.html">
<meta property="og:site_name" content="Live in the Future, then Build What's Missing">
<meta property="og:description" content="3. Logistic Regression and Regularization&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x903B;&amp;#x8F91;&amp;#x56DE;&amp;#x5F52;&amp;#x5206;&amp;#x6790;&amp;#xFF08;&amp;#x5206;&amp;#x7C7B;&amp;#x95EE;&amp;#x9898;&amp;#x6C42;&amp;#x89E3">
<meta property="og:image" content="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-01.png">
<meta property="og:image" content="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-02.png">
<meta property="og:image" content="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-03.png">
<meta property="og:image" content="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-04.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning By Stanford University Week 3">
<meta name="twitter:description" content="3. Logistic Regression and Regularization&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x903B;&amp;#x8F91;&amp;#x56DE;&amp;#x5F52;&amp;#x5206;&amp;#x6790;&amp;#xFF08;&amp;#x5206;&amp;#x7C7B;&amp;#x95EE;&amp;#x9898;&amp;#x6C42;&amp;#x89E3">
<meta name="twitter:creator" content="@xiaozhenliu">
<link rel="publisher" href="110358754558341446765">

    
    <link rel="alternative" href="/atom.xml" title="Live in the Future, then Build What&#39;s Missing" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Live in the Future, then Build What&#39;s Missing" title="Live in the Future, then Build What&#39;s Missing"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Live in the Future, then Build What&#39;s Missing">Live in the Future, then Build What&#39;s Missing</a></h1>
				<h2 class="blog-motto">刘虓震的技术笔记</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Homepage | 首页</a></li>
					
						<li><a href="/http://liuxiaozhen.com">Blog | 博客</a></li>
					
						<li><a href="/archive">Archives | 归档</a></li>
					
						<li><a href="/about">About | 关于</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:tech.liuxiaozhen.com">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2016/05/14/Machine-Learning-W3/" title="Machine Learning By Stanford University Week 3" itemprop="url">Machine Learning By Stanford University Week 3</a>
  </h1>
  <p class="article-author">By
       
		<a href="https://plus.google.com/110358754558341446765?rel=author" title="Liu Xiaozhen" target="_blank" itemprop="author">Liu Xiaozhen</a>
		
  <p class="article-time">
    <time datetime="2016-05-14T15:22:21.000Z" itemprop="datePublished"> 发表于 2016-05-14</time>
    
  </p>
</header>
	<div class="article-content">
		
		<h1 id="3-_Logistic_Regression_and_Regularization">3. Logistic Regression and Regularization</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x903B;&#x8F91;&#x56DE;&#x5F52;&#x5206;&#x6790;&#xFF08;&#x5206;&#x7C7B;&#x95EE;&#x9898;&#x6C42;&#x89E3;&#xFF09;&#x53CA;&#x6B63;&#x5219;&#x5316;&#x65B9;&#x6CD5;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 March session.</strong></p>
<h2 id="3-1_Logistic_Regression">3.1 Logistic Regression</h2><h3 id="3-1-1_Classification_Problems_and_Logistic_Regression_Model">3.1.1 Classification Problems and Logistic Regression Model</h3><h4 id="a)_Classification_Problems">a) Classification Problems</h4><ul>
<li>Email&#xFF1A; spam/not spam</li>
<li>Online transactions: froudulent or not</li>
<li>Tumor: malignant/benign</li>
</ul>
<p>$y\in{0,1}$</p>
<ul>
<li>0: &#x201C;Negative Class&#x201D;</li>
<li>1: &#x201C;Positive Class&#x201D;</li>
</ul>
<p>Use threshold classifier output $h_\theta(x)$ at 0.5</p>
<ul>
<li>If $h_\theta(x) \geq 0.5$, predict &#x201C;y=1&#x201D;</li>
<li>If $h_\theta(x) &lt; 0.5$, predict &#x201C;y=0&#x201D; </li>
</ul>
<h4 id="b)_Logistic_Regression_Model">b) Logistic Regression Model</h4><p>Want $0\leq h_\theta(x) \leq 1$</p>
<p>$h_\theta(x) = g(\theta^Tx)$<br>The sigmoid function: $g(z) = \frac 1{1+e^{-z}}$<br>$h_\theta(x) =\frac 1{1+e^{-\theta^Tx}}$</p>
<p>whenever $z \geq 0$, or $\theta^Tx \geq 0$,y =1</p>
<h3 id="3-1-2_Decision_Boundary">3.1.2 Decision Boundary</h3><h4 id="a)_Decision_Boundary">a) Decision Boundary</h4><p>$h_\theta(x) = g(\theta_0+\theta_1x_1+\theta_2x_2)$</p>
<h4 id="b)_Non-linear_decision_boundaries">b) Non-linear decision boundaries</h4><p>$h_\theta(x) = g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)$</p>
<p>Predict &#x201C;y=1&#x201D; if $-1+x_1^2+x_2^2 \geq 0$</p>
<h2 id="3-1-3_Cost_Function">3.1.3 Cost Function</h2><p>Logistic regression:</p>
<p>$$\text{Cost}(h_\theta(x^{(i)}),y^{(i)}) = \frac12\left(h_\theta(x^{(i)})-y^{(i)}\right)^2$$</p>
<p>&#x201C;non-convex&#x201D; v.s. &#x201C;convex&#x201D;</p>
<p>$$\text{Cost}(h_\theta(x),y)=\begin{cases}\quad-\log(h_\theta(x))<br>\quad\text{if } y = 1\<br>-\log(1-h_\theta(x))\quad\text{if }y =0<br>\end{cases}$$</p>
<p>Cost = 0 if y=1, $h_\theta(x)=1$<br>But as $h_\theta(x)\rightarrow 0$, Cost $\rightarrow \infty$</p>
<p>More compact way:</p>
<p>$\text{Cost}(h_\theta(x),y)=-y\log\left(h_\theta(x)\right)-(1-y)\log\left(1-h_\theta(x)\right)<br>$</p>
<p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]$$</p>
<p>To fit parameters $\theta$:<br>$\min_\theta J (\theta)$</p>
<p>Repeat {</p>
<p>$$\theta_j:=\theta_j-\alpha\sum_{i=1}^m \left( h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(j)}$$</p>
<p>}</p>
<p>Algorithm looks identical to linear regression!</p>
<h3 id="3-1-4_Optimization_algorithm">3.1.4 Optimization algorithm</h3><ul>
<li>Gradient descent</li>
<li>Conjugate gradient</li>
<li>BFGS</li>
<li>L-BFGS</li>
</ul>
<p>Advantages:</p>
<ul>
<li><p>No need to manually pick $\alpha$</p>
</li>
<li><p>Often faster than gradient descent</p>
</li>
</ul>
<p>Disadvantages:</p>
<ul>
<li>More complex</li>
</ul>
<h3 id="3-1-5_Multiclass_Classification">3.1.5 Multiclass Classification</h3><h4 id="a)_Problem_examples">a) Problem examples</h4><ul>
<li>Email foldering/tagging: work, friends, family, hobby</li>
<li>Medical diagrams: not ill, cold, flu</li>
<li>Weather: sunny, cloudy, rain, snow</li>
</ul>
<h4 id="b)_One-vs-all_(one-vs-rest)">b) One-vs-all (one-vs-rest)</h4><p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-01.png" alt=""></p>
<p>&#x5C06;&#x9700;&#x8981;&#x5206;&#x4E3A;N&#x7C7B;&#x7684;&#x6570;&#x636E;&#x62C6;&#x5206;&#x6210; N&#x4E2A;0/1&#xFF08;&#x662F;&#xFF0F;&#x5426;&#xFF09;&#x95EE;&#x9898;&#x3002;</p>
<p>Train a logistic regression classifier $h_\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$.</p>
<p>On a new input $x$, to make a prediction, pick the class $i$ that maximizes $\max h_\theta^{(i)}(x)$.</p>
<h2 id="3-2_Regularization_&#x6B63;&#x5219;&#x5316;">3.2 Regularization &#x6B63;&#x5219;&#x5316;</h2><h3 id="3-2-1_Overfitting_Problems_&#x8FC7;&#x62DF;&#x5408;&#x95EE;&#x9898;">3.2.1 Overfitting Problems &#x8FC7;&#x62DF;&#x5408;&#x95EE;&#x9898;</h3><h4 id="a)_Example:_Linear_Regression_(housing_prices)">a) Example: Linear Regression (housing prices)</h4><p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-02.png" alt=""></p>
<p>&#x5BF9;&#x4E8E;&#x623F;&#x5C4B;&#x4EF7;&#x683C;&#x7684;&#x4E09;&#x79CD;&#x62DF;&#x5408;&#x66F2;&#x7EBF;&#x4E0E;&#x5B9E;&#x9645;&#x6570;&#x636E;&#x7684;&#x7B26;&#x5408;&#x60C5;&#x51B5;&#xFF1A;</p>
<ul>
<li>&#x4E00;&#x5143;&#x7EBF;&#x6027;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;underfit, high bias</li>
<li>&#x4E00;&#x5143;&#x4E8C;&#x6B21;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;just right</li>
<li>&#x4E00;&#x5143;&#x56DB;&#x6B21;&#x8868;&#x8FBE;&#x5F0F;&#xFF1A;overfit, high variance</li>
</ul>
<p><strong>Overfitting:</strong> If we have too many features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples (predict prices on new examples).</p>
<h4 id="b)_Example:_Logistic_Regression">b) Example: Logistic Regression</h4><p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-03.png" alt=""></p>
<h4 id="Addressing_overfitting:">Addressing overfitting:</h4><ul>
<li>Reduce number of features:<ul>
<li>Manually select which features to keep</li>
<li>Model selection algorithm (later in course)</li>
</ul>
</li>
<li>Regularization:<ul>
<li>Keep all the features, but reduce magnitude/values of parameters $\theta_j$.</li>
<li>Works well when we have a lot of features, each of which contributes a bit to predicting $y$.</li>
</ul>
</li>
</ul>
<h3 id="3-2-2_Cost_Function">3.2.2 Cost Function</h3><h4 id="a)_Intuition">a) Intuition</h4><p><img src="/2016/05/14/Machine-Learning-W3/Coursera-ml-w3-04.png" alt=""></p>
<p>Suppose we penalize and make $\theta_3,\theta_4$ really small.</p>
<p>$$\min_\theta\frac1{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2 +1000\theta_3^2+1000\theta_4^2$$</p>
<p>$\theta_3,\theta_4$ will be very small.</p>
<h4 id="b)_Regularization">b) Regularization</h4><p>Small values for parameters $\theta_0, \theta_1, &#x2026;, \theta_n$</p>
<ul>
<li>&#x201C;Simpler&#x201D; hypothesis</li>
<li>Less prone to overfitting</li>
</ul>
<p><strong>Cost Function</strong><br>$$<br>J(\theta) = \frac1{2m}\left[\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{j=1}^n\theta_j^2\right]<br>$$</p>
<p>$\theta_0$ is excluded as a convention.</p>
<p>If $\lambda$ is too large, we might have underfitting problems. </p>
<h3 id="3-2-3_Regularized_Linear_Regression">3.2.3 Regularized Linear Regression</h3><h4 id="a)_Gradient_descent">a) Gradient descent</h4><p>Repeat {<br>$$\theta_0:=\theta_0-\alpha\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_0^{(i)}$$</p>
<p>$$\theta_j:=\theta_j-\alpha\left[\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}+\frac{\lambda}m\theta_j\right]$$</p>
<p>}</p>
<p>$$<br>\theta_j := \theta_j(1-\alpha\frac{\lambda}m)-\alpha\frac1m\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}<br>$$</p>
<p>$1-\alpha\frac{\lambda}m&lt;1$. Therefore, use $\theta_j^2$ as an approximation</p>
<h4 id="b)_Normal_equation">b) Normal equation</h4><p>$$<br>X = \begin{bmatrix}<br>(x^{(1)})^T\<br>&#x2026;\<br>(x^{(m)})^T\<br>\end{bmatrix}$$</p>
<p>$$<br>y = \begin{bmatrix}<br>(y^{(1)})^T\<br>&#x2026;\<br>(y^{(m)})^T\<br>\end{bmatrix}$$</p>
<p>To minimize $J(\theta)$</p>
<p>$$\theta = \left(X^TX+\lambda \begin{bmatrix}<br>0&amp;0&amp;0&amp;&#x2026;&amp;0\<br>0&amp;1&amp;0&amp;&#x2026;&amp;0\<br>0&amp;0&amp;1&amp;&#x2026;&amp;0\<br>&#x2026;&amp;&#x2026;&amp;&#x2026;&amp;1&amp;&#x2026;\<br>0&amp;0&amp;0&amp;&#x2026;&amp;1\<br>\end{bmatrix}\right)^{-1}X^Ty$$</p>
<h4 id="c)_Non-invertibility_(optional/advanced)">c) Non-invertibility (optional/advanced)</h4><p>Suppose $m\leq n$,<br>(where m: number of examples; n: number of features)</p>
<p>$$\theta = (X^TX)^{-1}X^Ty$$</p>
<p>$X^TX$ is non-invertible/singular. In Octave/MATLAB, use <code>pinv</code> instead of <code>inv</code>.</p>
<p>If $\lambda \gt 0,$<br>$$<br>\theta = \left(X^TX+\lambda \begin{bmatrix}<br>0&amp;0&amp;0&amp;&#x2026;&amp;0\<br>0&amp;1&amp;0&amp;&#x2026;&amp;0\<br>0&amp;0&amp;1&amp;&#x2026;&amp;0\<br>&#x2026;&amp;&#x2026;&amp;&#x2026;&amp;1&amp;&#x2026;\<br>0&amp;0&amp;0&amp;&#x2026;&amp;1\<br>\end{bmatrix}\right)^{-1}X^Ty<br>$$</p>
<h3 id="3-2-4_Regularized_Logistic_Regression">3.2.4 Regularized Logistic Regression</h3><h4 id="a)_Cost_function:">a) Cost function:</h4><p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$$</p>
<h4 id="b)_Gradient_descent">b) Gradient descent</h4><p>Repeat {<br>$$\theta_0:=\theta_0-\alpha\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_0^{(i)}$$</p>
<p>$$\theta_j:=\theta_j-\alpha\left[\frac1m \sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)x_j^{(i)}+\frac{\lambda}m\theta_j\right]$$</p>
<p>}</p>
<p>where $h_\theta(x)=\frac1{1+e^{-\theta^TX}}$</p>
<h4 id="c)_Advaced_optimization">c) Advaced optimization</h4><p><code>function [jVal, gradient] = costFunction(theta)</code></p>
<p><code>jVal =</code>[code to compute $J(\theta)$];</p>
<p>$$J(\theta)= - \frac 1m\left[\sum_{i=1}^m y^{(i)}\log h_\theta\left(x^{(i)}\right)+\left(1-y^{(i)}\right)\log\left(1-h_\theta\left(x^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2$$</p>
<p><code>gradient(1)</code> = [code to compute $\frac\partial{\partial\theta_0}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_0^{(i)}$$</p>
<p><code>gradient(2)</code> = [code to compute $\frac\partial{\partial\theta_1}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_1^{(i)}&#xFF0B;\frac\lambda m\theta_1$$</p>
<p><code>gradient(3)</code> = [code to compute $\frac\partial{\partial\theta_2}J(\theta)$];</p>
<p>$$\frac1m \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)x_2^{(i)}&#xFF0B;\frac\lambda m\theta_2$$<br>&#x2026;</p>
<p><code>gradient(n+1)</code> = [code to compute $\frac\partial{\partial\theta_n}J(\theta)$];</p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/Coursera/">Coursera</a><a href="/tags/Logistic-Regression/">Logistic Regression</a><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Regularization/">Regularization</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="http://tech.liuxiaozhen.com/2016/05/14/Machine-Learning-W3/" data-title="Machine Learning By Stanford University Week 3 | Live in the Future, then Build What&#39;s Missing" data-tsina="hohcn" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2016/06/12/Machine-Learning-W5/" title="Machine Learning By Stanford University Week 5">
  <strong>上一篇：</strong><br/>
  <span>
  Machine Learning By Stanford University Week 5</span>
</a>
</div>


<div class="next">
<a href="/2016/04/28/udacity-data-analyst-nanodegree-1/"  title="数据分析师养成计划（2）">
 <strong>下一篇：</strong><br/> 
 <span>数据分析师养成计划（2）
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2016/05/14/Machine-Learning-W3/" data-title="Machine Learning By Stanford University Week 3" data-url="http://tech.liuxiaozhen.com/2016/05/14/Machine-Learning-W3/"></div>
</section>


</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/Coursera/" title="Coursera">Coursera<sup>5</sup></a></li>
			
		
			
				<li><a href="/tags/Machine-Learning/" title="Machine Learning">Machine Learning<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/Linear-Regression/" title="Linear Regression">Linear Regression<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Neural-Networks/" title="Neural Networks">Neural Networks<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python/" title="Python">Python<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Udacity/" title="Udacity">Udacity<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Statistics/" title="Statistics">Statistics<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Nanodegree/" title="Nanodegree">Nanodegree<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Data-Analyst/" title="Data Analyst">Data Analyst<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Logistic-Regression/" title="Logistic Regression">Logistic Regression<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Regularization/" title="Regularization">Regularization<sup>1</sup></a></li>
			
		
			
		
			
		
			
		
			
		
			
		
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="http://wuchong.me" target="_blank" title="Jark&#39;s Blog">Jark&#39;s Blog</a>
            
          </li>
        
    </ul>
</div>

  

<div class="doubanshow">
<p class="asidetitle">豆瓣秀</p>
<div>
<script type="text/javascript" src="http://www.douban.com/service/badge/67534041/?show=collection&amp;n=12&amp;columns=3&amp;hidelogo=yes&amp;hideself=yes&amp;cat=book|movie" ></script>
</div>
</div>


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Never doubt that a small group of thoughtful, committed citizens can change the world; <br/>
			indeed, it&#39;s the only thing that ever has.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/hohcn" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/xiaozhenliu" target="_blank" class="icon-github" title="github"></a>
		
		
		
		<a href="https://twitter.com/xiaozhenliu" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		
		<a href="https://www.linkedin.com/in/xiaozhenliu" target="_blank" class="icon-linkedin" title="linkedin"></a>
		
		
		<a href="https://www.douban.com/people/67534041" target="_blank" class="icon-douban" title="豆瓣"></a>
		
		
		<a href="http://www.zhihu.com/people/xiaozhenliu" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		<a href="https://plus.google.com/110358754558341446765?rel=author" target="_blank" class="icon-google_plus" title="Google+"></a>
		
		
		<a href="mailto:zjuhoh@gmail.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		
				<div class="cc-license">
          <a href="http://creativecommons.org/licenses/by-nc/4.0" class="cc-opacity" target="_blank">
            <img src="/img/cc-by-nc.svg" alt="Creative Commons" />
          </a>
        </div>
    

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2016 
		
		<a href="/about" target="_blank" title="Liu Xiaozhen">Liu Xiaozhen</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>



<script type="text/javascript">
  var duoshuoQuery = {short_name:"techlxz## e.g. wuchong   your duoshuo short name."};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 







<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-61561823-1', 'tech.liuxiaozhen.com');  
ga('send', 'pageview');
</script>





<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  
<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config(null);
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
</body>
</html>
