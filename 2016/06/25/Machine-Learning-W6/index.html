<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning By Stanford University Week 6 | 刘虓震的技术笔记</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="6. Machine Learning Application Advice and System Design&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x5E94;&amp;#x7528;&amp;#x4E2D;&amp;#x7684;&amp;#x6CE8;&amp;#x610F;&amp;#x4E8B;">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning By Stanford University Week 6">
<meta property="og:url" content="http://tech.liuxiaozhen.com/2016/06/25/Machine-Learning-W6/index.html">
<meta property="og:site_name" content="刘虓震的技术笔记">
<meta property="og:description" content="6. Machine Learning Application Advice and System Design&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x5E94;&amp;#x7528;&amp;#x4E2D;&amp;#x7684;&amp;#x6CE8;&amp;#x610F;&amp;#x4E8B;">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-01.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-02.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-03.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-04.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-05.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png">
<meta property="og:image" content="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning By Stanford University Week 6">
<meta name="twitter:description" content="6. Machine Learning Application Advice and System Design&amp;#x672C;&amp;#x5468;&amp;#x8BFE;&amp;#x7A0B;&amp;#x4ECB;&amp;#x7ECD;&amp;#x4E86;&amp;#x673A;&amp;#x5668;&amp;#x5B66;&amp;#x4E60;&amp;#x5E94;&amp;#x7528;&amp;#x4E2D;&amp;#x7684;&amp;#x6CE8;&amp;#x610F;&amp;#x4E8B;">
  
    <link rel="alternative" href="/atom.xml" title="刘虓震的技术笔记" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">刘虓震的技术笔记</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Live in the Future, then Build What&#39;s Missing</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">首页</a>
        
          <a class="main-nav-link" href="http://tech.liuxiaozhen.com">技术</a>
        
          <a class="main-nav-link" href="/archives">所有文章</a>
        
          <a class="main-nav-link" href="/about">关于</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="q" value="site:http://tech.liuxiaozhen.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Machine-Learning-W6" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/06/25/Machine-Learning-W6/" class="article-date">
  <time datetime="2016-06-25T14:24:12.000Z" itemprop="datePublished">2016-06-25</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Machine Learning By Stanford University Week 6
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="6-Machine-Learning-Application-Advice-and-System-Design"><a href="#6-Machine-Learning-Application-Advice-and-System-Design" class="headerlink" title="6. Machine Learning Application Advice and System Design"></a>6. Machine Learning Application Advice and System Design</h1><p>&#x672C;&#x5468;&#x8BFE;&#x7A0B;&#x4ECB;&#x7ECD;&#x4E86;&#x673A;&#x5668;&#x5B66;&#x4E60;&#x5E94;&#x7528;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x4E8B;&#x9879;&#x4EE5;&#x53CA;&#x7CFB;&#x7EDF;&#x8BBE;&#x8BA1;&#x3002;</p>
<a id="more"></a>
<p><strong>This note is for the Stanford University online course &#x201C;Machine Learning&#x201D; taught by Andrew Ng on Coursera.org, 2016 May session.</strong></p>
<h2 id="6-1-Evaluating-a-Learning-Algorithm"><a href="#6-1-Evaluating-a-Learning-Algorithm" class="headerlink" title="6.1 Evaluating a Learning Algorithm"></a>6.1 Evaluating a Learning Algorithm</h2><p>Goal: Learn How to choose one of the most promising avenues to spend your time pursuing. </p>
<h3 id="6-1-1-Deciding-what-to-try-next"><a href="#6-1-1-Deciding-what-to-try-next" class="headerlink" title="6.1.1 Deciding what to try next"></a>6.1.1 Deciding what to try next</h3><p><strong>Debugging a learning algorithm</strong></p>
<p>Suppose you have implemented regularized linear regression to predict housing prices. </p>
<p>However, when you test your hypothesis on a new set of hourses, you find that it makes unacceptably large errors in its predictions. What should you try next?</p>
<ul>
<li>Get more training examples</li>
<li>Try smaller sets of features </li>
<li>Try getting additional features</li>
<li>Try adding polynomial features $(x_1^2, x_2^2, x_1x_2, \text{etc})$</li>
<li>Try decreasing $\lambda$</li>
<li>Try increasing $\lambda$  </li>
</ul>
<p>WRONG: Randomly pick one of these options</p>
<p>CORRECT: Machine Learning Diagnostic</p>
<p>A test that you can run to gain insight what is/isn&#x2019;t working with a learning algorithm, and gain guidance as to how best to improve its performance. </p>
<h3 id="6-1-2-Evaluating-a-Hypothesis"><a href="#6-1-2-Evaluating-a-Hypothesis" class="headerlink" title="6.1.2 Evaluating a Hypothesis"></a>6.1.2 Evaluating a Hypothesis</h3><p>Example: Using housing sizes to predict prices.</p>
<p>Method: (randomly) choose 70% of the dataset (samples) as the training set, the other 30% as the test set. </p>
<p>Training set: $m$ number of samples; $x^{(1)},y^{(1)}&#x2026;x^{(m)},y^{(m)}$</p>
<p>Test set: $m<em>test$ number of samples<br>$x</em>{test}^{(1)},y<em>{test}^{(1)}&#x2026;x</em>{test}^{(m)},y_{text}^{(m)}$</p>
<p><strong>Training/testing procedure for linear regression</strong></p>
<ul>
<li>Learn parameter $\theta$ from training data (minimizing training error $J(\theta)$)</li>
<li>Compute test set error: </li>
</ul>
<script type="math/tex; mode=display">J_{test}(\theta)=\frac1{2m_{test}}\sum_{i=1}^{m_{test}}\left(h_\theta(x_{test}^{(i)})-y_{test}^{(i)}\right)^2</script><script type="math/tex; mode=display">J_{test}(\theta)=\frac1{2m_{test}}\sum_{i=1}^{m_{test}}y_{test}^{(i)}\log h_\theta(x_{test}^{(i)})+(1-y_{test}^{(i)})\log h_\theta(x_{test}^{(i)})</script><ul>
<li>Misclassification error (0/1 misclassification error);</li>
</ul>
<script type="math/tex; mode=display">err(h_\theta(x),y)=\begin{cases}1\quad\text{if }h_\theta(x)\geq0.5, y=0\text{ or if } h_\theta(x)\leq0.5, y=1\\0\quad\text{otherwise}\end{cases}</script><script type="math/tex; mode=display">\text{Test error} = \frac1{m_{test}}\sum_{i=1}^{m_{test}}err\left(h_\theta(x_{test}^{(i)}),y_{test}^{(i)}\right)\</script><h3 id="6-1-3-Model-Selection-and-Train-Validation-Test-Sets"><a href="#6-1-3-Model-Selection-and-Train-Validation-Test-Sets" class="headerlink" title="6.1.3 Model Selection and Train/Validation/Test Sets"></a>6.1.3 Model Selection and Train/Validation/Test Sets</h3><p><strong>Overfitting example</strong></p>
<p>Once parameters $\theta_0,\theta_1,&#x2026;,\theta_4$ were fit to some set of data (traning set), the error of the parameters as measured on that data (the traing error $J(\theta)$) is likely to be lower than the actual generalization error.</p>
<p><strong>Model selection</strong></p>
<ol>
<li>$h_\theta(x) = \theta_0+\theta_1x$</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+\theta_2x^2$</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+&#x2026;+\theta_3x^2$<br>&#x2026;</li>
<li>$h_\theta(x) = \theta_0+\theta_1x+&#x2026;+\theta_10x^10$</li>
</ol>
<p>Assume a new parameter $d$ = degree of polynomial. </p>
<p>Test dataset cost functions: $J_{test}(\theta_j)$ ($j$ is from 1 to $d$)</p>
<p>Problem: degree of polynomial is chosen based on the test dataset, therefore cannot guarantee the generalization ability to further data. </p>
<p><strong>Solution</strong>: divide the original dataset to a training set, a cross validation set (CV), and a test set. </p>
<p><strong>Train/validation/test error</strong></p>
<p>Use the CV set to select the model. Then estimate generalization error $J_{test}(\theta)$</p>
<h2 id="6-2-Bias-vs-Variance"><a href="#6-2-Bias-vs-Variance" class="headerlink" title="6.2 Bias vs. Variance"></a>6.2 Bias vs. Variance</h2><h3 id="6-2-1-Diagnosing-Bias-vs-Variance"><a href="#6-2-1-Diagnosing-Bias-vs-Variance" class="headerlink" title="6.2.1 Diagnosing Bias vs. Variance"></a>6.2.1 Diagnosing Bias vs. Variance</h3><p>High bias - Underfit<br>High variance - Overfit</p>
<p>Training error: </p>
<script type="math/tex; mode=display">J_{train}(\theta)=\frac1{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2</script><p>Cross validation error: </p>
<script type="math/tex; mode=display">J_{cv}(\theta)=\frac1{2m_{cv}}\sum_{i=1}^{m_{cv}}\left(h_\theta(x_{cv}^{(i)})-y_{cv}^{(i)}\right)^2</script><p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-01.png" alt=""></p>
<h3 id="6-2-2-Regularization-and-Bias-Variance"><a href="#6-2-2-Regularization-and-Bias-Variance" class="headerlink" title="6.2.2 Regularization and Bias/Variance"></a>6.2.2 Regularization and Bias/Variance</h3><p><strong>Linear regression with regularization</strong></p>
<p>Large $\lambda$: high bias, underfit</p>
<p>Small $\lambda$: high variance, overfit</p>
<p><strong>Choosing the regularization parameter $\lambda$</strong></p>
<ul>
<li><p>have some range of $\lambda$ values: e.g. [0,0.01,0.02,0.04,0.08&#x2026;10]</p>
</li>
<li><p>calculate $\min J(\theta)$ for each $\lambda$ -&gt; $J_{cv}(\theta^{(?)})$</p>
</li>
<li><p>pick the lowest $J<em>{cv}(\theta^{(?)})$ $\theta^{(5)}$. Test error: $J</em>{test}(\theta^{(5)})$</p>
</li>
<li><p>Plot $J<em>{train}(\theta)$ and $J</em>{cv}(\theta)$ v.s. $\lambda$</p>
</li>
</ul>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-02.png" alt=""></p>
<h3 id="6-2-3-Learning-Curves"><a href="#6-2-3-Learning-Curves" class="headerlink" title="6.2.3 Learning Curves"></a>6.2.3 Learning Curves</h3><p>&#x589E;&#x52A0;&#x6837;&#x672C;&#x6570;&#x662F;&#x5426;&#x80FD;&#x51CF;&#x5C11;&#x8BEF;&#x5DEE;&#xFF1F;</p>
<p>Learning curves: plot error v.s. m (training set size)</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-03.png" alt=""></p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-04.png" alt=""></p>
<p>High bias:</p>
<p>If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much.</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-05.png" alt=""></p>
<p>High variance:</p>
<p>If a learning algorithm is suffering from high variance, getting more traning data is likely to help.</p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png" alt=""></p>
<h3 id="6-2-4-Deciding-What-to-Do-Next-Revisited"><a href="#6-2-4-Deciding-What-to-Do-Next-Revisited" class="headerlink" title="6.2.4 Deciding What to Do Next Revisited"></a>6.2.4 Deciding What to Do Next Revisited</h3><p><strong>Debugging a learning algorithm</strong></p>
<p>Suppose you have implemented regularized linear regression to predict housing prices. </p>
<p>However, when you test your hypothesis on a new set of hourses, you find that it makes unacceptably large errors in its predictions. What should you try next?</p>
<ul>
<li>Get more training examples -&gt; <em>fixes high variance</em></li>
<li>Try smaller sets of features -&gt; <em>fixes high variance</em></li>
<li>Try getting additional features -&gt; <em>fixes high bias</em></li>
<li>Try adding polynomial features $(x_1^2, x_2^2, x_1x_2, \text{etc})$ -&gt; <em>fixes high bias</em></li>
<li>Try decreasing $\lambda$ -&gt; <em>fixes high bias</em></li>
<li>Try increasing $\lambda$ -&gt; <em>fixes high variance</em></li>
</ul>
<p><strong>Neural networks and overfitting</strong></p>
<p><img src="/2016/06/25/Machine-Learning-W6/Coursera-ml-w6-06.png" alt=""></p>
<p>Using a single hidden layer is a reasonable default. But if you want to choose the number of hidden layers, one other thing you can try is find yourself a training cross-validation, and test set split and try training neural networks with one hidden layer or two hidden layers or three hidden layers and see which of those neural networks performs best on the cross-validation sets. </p>
<h2 id="6-3-Building-a-Spam-Classifier"><a href="#6-3-Building-a-Spam-Classifier" class="headerlink" title="6.3 Building a Spam Classifier"></a>6.3 Building a Spam Classifier</h2><h3 id="6-3-1-Prioritizing-What-to-Work-on"><a href="#6-3-1-Prioritizing-What-to-Work-on" class="headerlink" title="6.3.1 Prioritizing What to Work on"></a>6.3.1 Prioritizing What to Work on</h3><h3 id="6-3-2-Error-Analysis"><a href="#6-3-2-Error-Analysis" class="headerlink" title="6.3.2 Error Analysis"></a>6.3.2 Error Analysis</h3><h2 id="6-4-Handling-Skewed-Data"><a href="#6-4-Handling-Skewed-Data" class="headerlink" title="6.4 Handling Skewed Data"></a>6.4 Handling Skewed Data</h2><p>Cancer classification example<br>1% error on test set (99% correct)</p>
<h3 id="Error-Metrics-for-Skewed-Classes"><a href="#Error-Metrics-for-Skewed-Classes" class="headerlink" title="Error Metrics for Skewed Classes"></a>Error Metrics for Skewed Classes</h3><h3 id="Trading-Off-Precision-and-Recall"><a href="#Trading-Off-Precision-and-Recall" class="headerlink" title="Trading Off Precision and Recall"></a>Trading Off Precision and Recall</h3><p>Logistic regression:<br>Predict 1 if<br>Predict 0 if<br>Suppose we want to predict y = 1 only if very confident</p>
<p>-&gt; Higher precision, lower recall.</p>
<p>Suppose we want to avoid missing too many cases of cancer (avoid false negatives).</p>
<p>-&gt; higher recall, lower precision</p>
<p><strong>$F_1$ Score (F score)</strong></p>
<p>How to compare precision/recall numbers?</p>
<p>The average of P and R is not a good indicator</p>
<p>$F_1$ score: $2\frac{PR}{P+R}$</p>
<h2 id="6-5-Using-Large-Data-Sets"><a href="#6-5-Using-Large-Data-Sets" class="headerlink" title="6.5 Using Large Data Sets"></a>6.5 Using Large Data Sets</h2><h3 id="Designing-a-high-accuracy-learning-system"><a href="#Designing-a-high-accuracy-learning-system" class="headerlink" title="Designing a high accuracy learning system"></a>Designing a high accuracy learning system</h3><p>e.g. Classify between confusable words. {to,two,too},{then,than}</p>
<p>Algorithms:</p>
<ul>
<li>Perceptron (Logistic regression)</li>
<li>Winnow</li>
<li>Memory-based</li>
<li>Naive Bayes</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://tech.liuxiaozhen.com/2016/06/25/Machine-Learning-W6/" data-id="civ9p4d9c0011p3wcy18yo02h" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Coursera/">Coursera</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Learning-Curves/">Learning Curves</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Model-Selection/">Model Selection</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Overfitting/">Overfitting</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Precision/">Precision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Recall/">Recall</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/07/06/Udacity-MLND-01/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习工程师之路（1）
        
      </div>
    </a>
  
  
    <a href="/2016/06/12/Machine-Learning-W5/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Machine Learning By Stanford University Week 5</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Coursera/">Coursera</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Data-Analyst/">Data Analyst</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Learning-Curves/">Learning Curves</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Linear-Regression/">Linear Regression</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Logistic-Regression/">Logistic Regression</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MLND/">MLND</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Machine-Learning/">Machine Learning</a><span class="tag-list-count">6</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model-Selection/">Model Selection</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Nanodegree/">Nanodegree</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Neural-Networks/">Neural Networks</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Overfitting/">Overfitting</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Precision/">Precision</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/">Python</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Recall/">Recall</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Regularization/">Regularization</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Statistics/">Statistics</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Udacity/">Udacity</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Coursera/" style="font-size: 20px;">Coursera</a><a href="/tags/Data-Analyst/" style="font-size: 10px;">Data Analyst</a><a href="/tags/Learning-Curves/" style="font-size: 10px;">Learning Curves</a><a href="/tags/Linear-Regression/" style="font-size: 15px;">Linear Regression</a><a href="/tags/Logistic-Regression/" style="font-size: 10px;">Logistic Regression</a><a href="/tags/MLND/" style="font-size: 10px;">MLND</a><a href="/tags/Machine-Learning/" style="font-size: 20px;">Machine Learning</a><a href="/tags/Model-Selection/" style="font-size: 10px;">Model Selection</a><a href="/tags/Nanodegree/" style="font-size: 15px;">Nanodegree</a><a href="/tags/Neural-Networks/" style="font-size: 10px;">Neural Networks</a><a href="/tags/Overfitting/" style="font-size: 10px;">Overfitting</a><a href="/tags/Precision/" style="font-size: 10px;">Precision</a><a href="/tags/Python/" style="font-size: 10px;">Python</a><a href="/tags/Recall/" style="font-size: 10px;">Recall</a><a href="/tags/Regularization/" style="font-size: 10px;">Regularization</a><a href="/tags/Statistics/" style="font-size: 15px;">Statistics</a><a href="/tags/Udacity/" style="font-size: 15px;">Udacity</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archive/2016/07/">July 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2016/06/">June 2016</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2016/05/">May 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2016/04/">April 2016</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2016/03/">March 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2015/12/">December 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archive/2015/04/">April 2015</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/07/06/Udacity-MLND-01/">机器学习工程师之路（1）</a>
          </li>
        
          <li>
            <a href="/2016/06/25/Machine-Learning-W6/">Machine Learning By Stanford University Week 6</a>
          </li>
        
          <li>
            <a href="/2016/06/12/Machine-Learning-W5/">Machine Learning By Stanford University Week 5</a>
          </li>
        
          <li>
            <a href="/2016/05/14/Machine-Learning-W3/">Machine Learning By Stanford University Week 3</a>
          </li>
        
          <li>
            <a href="/2016/04/28/udacity-data-analyst-nanodegree-1/">数据分析师养成计划（2）</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 Liu Xiaozhen<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">首页</a>
  
    <a href="http://tech.liuxiaozhen.com" class="mobile-nav-link">技术</a>
  
    <a href="/archives" class="mobile-nav-link">所有文章</a>
  
    <a href="/about" class="mobile-nav-link">关于</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>

<!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config(null);
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="custom_mathjax_source">
</script>
<!-- End: Injected MathJax -->
</body>
</html>